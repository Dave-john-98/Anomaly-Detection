{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0871944f-93ee-4487-bdb4-97e8883d5c60",
   "metadata": {},
   "source": [
    "## Preliminary Data Processing\n",
    "\n",
    "In this initial step, we load the dataset `XYZloan_default_selected_vars.csv` we previously used from homework 3. Loading the dataset into a pandas DataFrame allows us to inspect its structure, ensuring that all variables are correctly formatted and ready for further exploration and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "739f9dd3-d861-45d4-92d7-2b8c43337267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_default</th>\n",
       "      <th>AP001</th>\n",
       "      <th>AP002</th>\n",
       "      <th>AP003</th>\n",
       "      <th>AP004</th>\n",
       "      <th>AP005</th>\n",
       "      <th>AP006</th>\n",
       "      <th>AP007</th>\n",
       "      <th>AP008</th>\n",
       "      <th>AP009</th>\n",
       "      <th>...</th>\n",
       "      <th>CD162</th>\n",
       "      <th>CD164</th>\n",
       "      <th>CD166</th>\n",
       "      <th>CD167</th>\n",
       "      <th>CD169</th>\n",
       "      <th>CD170</th>\n",
       "      <th>CD172</th>\n",
       "      <th>CD173</th>\n",
       "      <th>MB005</th>\n",
       "      <th>MB007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017/7/6 10:21</td>\n",
       "      <td>ios</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1449.0</td>\n",
       "      <td>1449.0</td>\n",
       "      <td>2249.0</td>\n",
       "      <td>2249.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>IPHONE7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017/4/6 12:51</td>\n",
       "      <td>h5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WEB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2017/7/1 14:11</td>\n",
       "      <td>h5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>WEB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2017/7/7 10:10</td>\n",
       "      <td>android</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>OPPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2017/7/6 14:37</td>\n",
       "      <td>h5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WEB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_default  AP001  AP002  AP003  AP004           AP005    AP006  AP007  \\\n",
       "0             1     31      2      1     12  2017/7/6 10:21      ios      3   \n",
       "1             0     27      1      1     12  2017/4/6 12:51       h5      5   \n",
       "2             0     33      1      4     12  2017/7/1 14:11       h5      4   \n",
       "3             0     34      2      4     12  2017/7/7 10:10  android      5   \n",
       "4             0     47      2      1     12  2017/7/6 14:37       h5      4   \n",
       "\n",
       "   AP008  AP009  ...  CD162  CD164  CD166  CD167   CD169   CD170   CD172  \\\n",
       "0      3      1  ...   13.0   13.0    0.0    0.0  1449.0  1449.0  2249.0   \n",
       "1      4      0  ...  -99.0  -99.0  -99.0  -99.0   -99.0   -99.0   -99.0   \n",
       "2      2      0  ...    3.0    2.0   33.0    0.0    33.0     0.0   143.0   \n",
       "3      5      0  ...    0.0    0.0    0.0    0.0     0.0     0.0     0.0   \n",
       "4      4      1  ...  -99.0  -99.0  -99.0  -99.0   -99.0   -99.0   -99.0   \n",
       "\n",
       "    CD173  MB005    MB007  \n",
       "0  2249.0    7.0  IPHONE7  \n",
       "1   -99.0    NaN      WEB  \n",
       "2   110.0    8.0      WEB  \n",
       "3     0.0   10.0     OPPO  \n",
       "4   -99.0    NaN      WEB  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "path = '/home/ritwikgoel/Downloads/john.csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df = df.drop(columns=['Unnamed: 0.1','Unnamed: 0', 'id'])\n",
    "\n",
    "# Check the first few rows to understand the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d622e18-bb6b-4090-972e-1041d302f3c7",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis - Data Structure and Summary Statistics\n",
    "\n",
    "To begin our analysis, we examine the overall structure and characteristics of the dataset.\n",
    "\n",
    "we assess the data types of each variable and verify that there are no missing values. This inspection is crucial to identify any potential issues with data types that may impact modeling later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8873221-5500-4b8b-a17e-5157ad56e652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TD022    19598\n",
       "TD023     7663\n",
       "TD024     3694\n",
       "TD025     2550\n",
       "TD026     1846\n",
       "TD027     1697\n",
       "TD028     1636\n",
       "TD029     1630\n",
       "TD044    79997\n",
       "TD048    79999\n",
       "TD051    79995\n",
       "TD054    79988\n",
       "TD055    79999\n",
       "TD061    79990\n",
       "TD062    79999\n",
       "PA022      381\n",
       "PA023      381\n",
       "PA028      381\n",
       "PA029      381\n",
       "PA030      381\n",
       "PA031      381\n",
       "CD008      381\n",
       "CD018      381\n",
       "CD071      381\n",
       "CD072      381\n",
       "CD088      381\n",
       "CD100      381\n",
       "CD101      381\n",
       "CD106      381\n",
       "CD107      381\n",
       "CD108      381\n",
       "CD113      381\n",
       "CD114      381\n",
       "CD115      381\n",
       "CD117      381\n",
       "CD118      381\n",
       "CD120      381\n",
       "CD121      381\n",
       "CD123      381\n",
       "CD130      381\n",
       "CD131      381\n",
       "CD132      381\n",
       "CD133      381\n",
       "CD135      381\n",
       "CD136      381\n",
       "CD137      381\n",
       "CD152      381\n",
       "CD153      381\n",
       "CD160      381\n",
       "CD162      381\n",
       "CD164      381\n",
       "CD166      381\n",
       "CD167      381\n",
       "CD169      381\n",
       "CD170      381\n",
       "CD172      381\n",
       "CD173      381\n",
       "MB005     2793\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values[missing_values > 0] # Shows columns with missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efef8a00-031c-4266-9799-970c361ebaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the specified columns from the dataframe based on proportion of NaN's\n",
    "columns_to_remove = ['TD044', 'TD048', 'TD051', 'TD054', 'TD055', 'TD061', 'TD062']\n",
    "df = df.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28b8ddb6-e44a-4809-a9c9-d89be7d6b518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_default        2\n",
       "AP001              37\n",
       "AP002               2\n",
       "AP003               5\n",
       "AP004               4\n",
       "AP005           55057\n",
       "AP006               4\n",
       "AP007               5\n",
       "AP008               5\n",
       "AP009               2\n",
       "TD001              21\n",
       "TD002              12\n",
       "TD005              25\n",
       "TD006              21\n",
       "TD009              39\n",
       "TD010              30\n",
       "TD013              46\n",
       "TD014              34\n",
       "TD015               8\n",
       "TD022               5\n",
       "TD023              11\n",
       "TD024              16\n",
       "TD025               1\n",
       "TD026               1\n",
       "TD027               1\n",
       "TD028               1\n",
       "TD029               1\n",
       "CR004               4\n",
       "CR005               6\n",
       "CR009           25883\n",
       "CR012               1\n",
       "CR015               5\n",
       "CR017               8\n",
       "CR018               9\n",
       "CR019              12\n",
       "PA022             172\n",
       "PA023             167\n",
       "PA028            5142\n",
       "PA029            4120\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the unique values of the columns (first 39)\n",
    "df.nunique().head(39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55d71866-4b3e-4158-9031-e0e0e8363f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PA031     4323\n",
       "CD008    31165\n",
       "CD018     2026\n",
       "CD071      513\n",
       "CD072      507\n",
       "CD088      648\n",
       "CD100      488\n",
       "CD101      317\n",
       "CD106      625\n",
       "CD107      433\n",
       "CD108      392\n",
       "CD113       62\n",
       "CD114       92\n",
       "CD115      456\n",
       "CD117      326\n",
       "CD118      675\n",
       "CD120      498\n",
       "CD121      846\n",
       "CD123      604\n",
       "CD130      619\n",
       "CD131      612\n",
       "CD132      662\n",
       "CD133      642\n",
       "CD135      806\n",
       "CD136      810\n",
       "CD137      867\n",
       "CD152    30592\n",
       "CD153    30507\n",
       "CD160      255\n",
       "CD162      366\n",
       "CD164      314\n",
       "CD166     5759\n",
       "CD167     5415\n",
       "CD169     8565\n",
       "CD170     8046\n",
       "CD172    10818\n",
       "CD173    10198\n",
       "MB005       29\n",
       "MB007      112\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the unique values of the columns (last 39)\n",
    "df.nunique().tail(39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "805174bc-804c-47b2-b03a-851a6fee18a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the specified columns from the dataframe based on the only having 1 unique value\n",
    "df = df.drop(columns=['CR012','TD025','TD026','TD027','TD028','TD029'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc9fbcd1-5ef2-4096-9529-3cd59dc84375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns (unique values below threshold):\n",
      "['AP001', 'AP002', 'AP003', 'AP004', 'AP006', 'AP007', 'AP008', 'AP009', 'TD001', 'TD002', 'TD005', 'TD006', 'TD009', 'TD010', 'TD013', 'TD014', 'TD015', 'TD022', 'TD023', 'TD024', 'CR004', 'CR005', 'CR015', 'CR017', 'CR018', 'CR019', 'PA022', 'PA023', 'CD071', 'CD072', 'CD088', 'CD100', 'CD101', 'CD106', 'CD107', 'CD108', 'CD113', 'CD114', 'CD115', 'CD117', 'CD118', 'CD120', 'CD121', 'CD123', 'CD130', 'CD131', 'CD132', 'CD133', 'CD135', 'CD136', 'CD137', 'CD160', 'CD162', 'CD164', 'MB005', 'MB007']\n",
      "Numerical columns (unique values above threshold):\n",
      "['AP005', 'CR009', 'PA028', 'PA029', 'PA030', 'PA031', 'CD008', 'CD018', 'CD152', 'CD153', 'CD166', 'CD167', 'CD169', 'CD170', 'CD172', 'CD173']\n",
      "\n",
      "Data types after conversion:\n",
      "loan_default       int64\n",
      "AP001           category\n",
      "AP002           category\n",
      "AP003           category\n",
      "AP004           category\n",
      "                  ...   \n",
      "CD170            float64\n",
      "CD172            float64\n",
      "CD173            float64\n",
      "MB005           category\n",
      "MB007           category\n",
      "Length: 73, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Set the threshold\n",
    "threshold = 1000\n",
    "\n",
    "# Get the number of unique values for each column\n",
    "unique_counts = df.nunique()\n",
    "\n",
    "# Create a list of columns that are considered categorical (i.e., unique values below the threshold)\n",
    "categorical_columns = unique_counts[unique_counts < threshold].index.tolist()\n",
    "\n",
    "# Remove 'loan_default' from the list of categorical columns if it's there\n",
    "categorical_columns = [col for col in categorical_columns if col != 'loan_default']\n",
    "\n",
    "# Create a list of columns that are considered numerical (i.e., unique values above the threshold)\n",
    "numerical_columns = unique_counts[unique_counts >= threshold].index.tolist()\n",
    "\n",
    "# Output the lists of categorical and numerical columns\n",
    "print(\"Categorical columns (unique values below threshold):\")\n",
    "print(categorical_columns)\n",
    "\n",
    "print(\"Numerical columns (unique values above threshold):\")\n",
    "print(numerical_columns)\n",
    "\n",
    "# You can also convert the identified categorical columns to category dtype if needed\n",
    "df[categorical_columns] = df[categorical_columns].astype('category')\n",
    "\n",
    "# Check the data types of the columns after conversion\n",
    "print(\"\\nData types after conversion:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d6a8a1-d361-4828-b9f9-d7913d53d679",
   "metadata": {},
   "source": [
    "### Enhanced Data Cleaning: Binning Numerical-Like Categorical Columns\n",
    "\n",
    "To enhance the data cleaning from the previous assignment, we dynamically bin numerical-like categorical columns into meaningful ranges. This reduces noise, simplifies representation, and improves interpretability. \n",
    "\n",
    "Key enhancements:\n",
    "- Special negative values (`-99`, `-98`) are treated as separate categories to retain their significance.\n",
    "- Dynamic binning divides values based on distribution, with bins labeled by their ranges (e.g., `[0 - 10)`).\n",
    "\n",
    "This preprocessing ensures the data is clean, consistent, and ready for modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e903354-72fe-4777-a869-6ddcf7ecd6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Cardinality Columns Processed:\n",
      "['AP001', 'AP002', 'AP003', 'AP004', 'AP007', 'AP008', 'AP009', 'TD001', 'TD002', 'TD005', 'TD006', 'TD009', 'TD010', 'TD013', 'TD014', 'TD015', 'CR004', 'CR005', 'CR015', 'CR017', 'CR018', 'CR019']\n",
      "High Cardinality Columns Processed with Binning:\n",
      "[]\n",
      "Updated DataFrame:\n",
      "   loan_default AP001 AP002 AP003 AP004           AP005    AP006 AP007 AP008  \\\n",
      "0             1    31     2     1    12  2017/7/6 10:21      ios     3     3   \n",
      "1             0    27     1     1    12  2017/4/6 12:51       h5     5     4   \n",
      "2             0    33     1     4    12  2017/7/1 14:11       h5     4     2   \n",
      "3             0    34     2     4    12  2017/7/7 10:10  android     5     5   \n",
      "4             0    47     2     1    12  2017/7/6 14:37       h5     4     4   \n",
      "\n",
      "  AP009  ... CD162 CD164 CD166 CD167   CD169   CD170   CD172   CD173 MB005  \\\n",
      "0     1  ...  13.0  13.0   0.0   0.0  1449.0  1449.0  2249.0  2249.0   7.0   \n",
      "1     0  ... -99.0 -99.0 -99.0 -99.0   -99.0   -99.0   -99.0   -99.0   NaN   \n",
      "2     0  ...   3.0   2.0  33.0   0.0    33.0     0.0   143.0   110.0   8.0   \n",
      "3     0  ...   0.0   0.0   0.0   0.0     0.0     0.0     0.0     0.0  10.0   \n",
      "4     1  ... -99.0 -99.0 -99.0 -99.0   -99.0   -99.0   -99.0   -99.0   NaN   \n",
      "\n",
      "     MB007  \n",
      "0  IPHONE7  \n",
      "1      WEB  \n",
      "2      WEB  \n",
      "3     OPPO  \n",
      "4      WEB  \n",
      "\n",
      "[5 rows x 73 columns]\n"
     ]
    }
   ],
   "source": [
    "# Set thresholds for high-cardinality and low-cardinality columns\n",
    "high_cardinality_threshold = 100\n",
    "\n",
    "# Identify numerical-like categorical columns\n",
    "numerical_like_categorical_cols = []\n",
    "for col in categorical_columns:\n",
    "    # Check if the column contains only numeric values (ignoring NaNs)\n",
    "    if df[col].dropna().apply(lambda x: str(x).isdigit()).all():\n",
    "        numerical_like_categorical_cols.append(col)\n",
    "\n",
    "# Split columns based on unique values\n",
    "high_cardinality_cols = [\n",
    "    col for col in numerical_like_categorical_cols if df[col].nunique() > high_cardinality_threshold\n",
    "]\n",
    "low_cardinality_cols = [\n",
    "    col for col in numerical_like_categorical_cols if df[col].nunique() <= high_cardinality_threshold\n",
    "]\n",
    "\n",
    "# Process low-cardinality columns (directly convert to categorical)\n",
    "for col in low_cardinality_cols:\n",
    "    df[col] = pd.Categorical(df[col])\n",
    "\n",
    "# Process high-cardinality columns (apply binning)\n",
    "for col in high_cardinality_cols:\n",
    "    # Convert to numeric type\n",
    "    df[col] = pd.to_numeric(df[col])\n",
    "\n",
    "    # Handle special negative values (-99 and -98)\n",
    "    negative_values = [-99, -98]\n",
    "    df[col] = df[col].replace(negative_values, np.nan)  # Temporarily replace special values\n",
    "\n",
    "\n",
    "    # Apply qcut for binning (excluding NaNs)\n",
    "    binned_data, bins = pd.qcut(\n",
    "        df[col].dropna(),\n",
    "        q=100,\n",
    "        duplicates=\"drop\",\n",
    "        retbins=True\n",
    "    )\n",
    "\n",
    "    # Create bin labels based on range\n",
    "    bin_labels = [\n",
    "        f\"[{int(bins[i])} - {int(bins[i+1])})\" if i < len(bins) - 2 else f\"[{int(bins[i])} - {int(bins[i+1])}]\"\n",
    "        for i in range(len(bins) - 1)\n",
    "    ]\n",
    "\n",
    "    # Replace column values with bin labels\n",
    "    df[col] = pd.cut(df[col], bins=bins, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "    # Reintroduce -99 and -98 as their own categories\n",
    "    for value in negative_values:\n",
    "        df[col] = df[col].cat.add_categories([f\"Special_{value}\"])\n",
    "        df[col].fillna(f\"Special_{value}\", inplace=True)\n",
    "\n",
    "# Check the updated dataframe\n",
    "print(\"Low Cardinality Columns Processed:\")\n",
    "print(low_cardinality_cols)\n",
    "print(\"High Cardinality Columns Processed with Binning:\")\n",
    "print(high_cardinality_cols)\n",
    "print(\"Updated DataFrame:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07425b6-1420-4dad-9176-4a89de05d1a5",
   "metadata": {},
   "source": [
    "### Numerical Column Processing and Date Handling\n",
    "\n",
    "For numerical columns, no scaling or transformation is applied, as both **GLM** and **AutoML** can handle the existing range of values, including `-99`, `-98`, and `NaN`. This preserves the original distribution and the significance of special values.\n",
    "\n",
    "Additionally, the column `AP005` is identified as a date field and converted to a datetime format for potential temporal analysis. Any non-date values are coerced into `NaT` to maintain consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29a2734b-ae84-43ba-8f67-51b7e547273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling 'AP005' separately as a date column and converting it to datetime format\n",
    "numerical_columns = [col for col in numerical_columns if col != 'AP005']\n",
    "date_column = ['AP005']\n",
    "df['AP005'] = pd.to_datetime(df['AP005'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3423a41c-18a5-4a93-b26e-90c97300967c",
   "metadata": {},
   "source": [
    "### Final Check: Data Types\n",
    "\n",
    "Before splitting the dataset, we perform a final check to ensure that:\n",
    "- **Categorical columns** are correctly processed and have the `category` data type.\n",
    "- **Numerical columns** are correctly recognized as numeric (`int64`, `float64`).\n",
    "\n",
    "This ensures consistency and compatibility with the GLM and AutoML models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46423939-f80e-4930-b73f-f18c9edea410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types for categorical columns:\n",
      "AP001    category\n",
      "AP002    category\n",
      "AP003    category\n",
      "AP004    category\n",
      "AP006    category\n",
      "AP007    category\n",
      "AP008    category\n",
      "AP009    category\n",
      "TD001    category\n",
      "TD002    category\n",
      "TD005    category\n",
      "TD006    category\n",
      "TD009    category\n",
      "TD010    category\n",
      "TD013    category\n",
      "TD014    category\n",
      "TD015    category\n",
      "TD022    category\n",
      "TD023    category\n",
      "TD024    category\n",
      "CR004    category\n",
      "CR005    category\n",
      "CR015    category\n",
      "CR017    category\n",
      "CR018    category\n",
      "CR019    category\n",
      "PA022    category\n",
      "PA023    category\n",
      "CD071    category\n",
      "CD072    category\n",
      "CD088    category\n",
      "CD100    category\n",
      "CD101    category\n",
      "CD106    category\n",
      "CD107    category\n",
      "CD108    category\n",
      "CD113    category\n",
      "CD114    category\n",
      "CD115    category\n",
      "CD117    category\n",
      "CD118    category\n",
      "CD120    category\n",
      "CD121    category\n",
      "CD123    category\n",
      "CD130    category\n",
      "CD131    category\n",
      "CD132    category\n",
      "CD133    category\n",
      "CD135    category\n",
      "CD136    category\n",
      "CD137    category\n",
      "CD160    category\n",
      "CD162    category\n",
      "CD164    category\n",
      "MB005    category\n",
      "MB007    category\n",
      "dtype: object\n",
      "\n",
      "Data types for numerical columns:\n",
      "CR009      int64\n",
      "PA028    float64\n",
      "PA029    float64\n",
      "PA030    float64\n",
      "PA031    float64\n",
      "CD008    float64\n",
      "CD018    float64\n",
      "CD152    float64\n",
      "CD153    float64\n",
      "CD166    float64\n",
      "CD167    float64\n",
      "CD169    float64\n",
      "CD170    float64\n",
      "CD172    float64\n",
      "CD173    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types for categorical columns\n",
    "print(\"Data types for categorical columns:\")\n",
    "print(df[categorical_columns].dtypes)\n",
    "\n",
    "# Check data types for numerical columns\n",
    "print(\"\\nData types for numerical columns:\")\n",
    "print(df[numerical_columns].dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a10a26-c474-40dc-af9b-89ac6a74c627",
   "metadata": {},
   "source": [
    "### Splitting the Cleaned Dataset to Train and Test\n",
    "\n",
    "The dataset is split into training (80%) and testing (20%) sets to evaluate model performance. The split is stratified to ensure the target variable (`loan_default`) maintains its class distribution in both sets. A random state is used for reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa21c008-b50b-457a-a969-e9f7cd313078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (64000, 72)\n",
      "Testing set size: (16000, 72)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop(columns=['loan_default'])  # Exclude the target variable\n",
    "y = df['loan_default']  # Target variable\n",
    "\n",
    "# Perform an 80/20 train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Confirm the split sizes\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Testing set size:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a37e41e2-6278-4b00-b589-1c2ab8f7929d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution:\n",
      "0    0.806406\n",
      "1    0.193594\n",
      "Name: loan_default, dtype: float64\n",
      "\n",
      "Test set class distribution:\n",
      "0    0.806375\n",
      "1    0.193625\n",
      "Name: loan_default, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "print(\"Training set class distribution:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTest set class distribution:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5e610c-7a9c-4b09-8cd3-4590f0251d63",
   "metadata": {},
   "source": [
    "### H2O Initialization and Data Upload\n",
    "\n",
    "The H2O environment is initialized to leverage its scalable machine learning framework for training and evaluating the GLM model. The preprocessed training and testing datasets are converted into H2O frames for compatibility.\n",
    "\n",
    "This step ensures the data is ready for model training within the H2O framework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26091c3c-da1d-4691-98bb-726806c46abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"11.0.25\" 2024-10-15; OpenJDK Runtime Environment (build 11.0.25+9-post-Ubuntu-1ubuntu122.04); OpenJDK 64-Bit Server VM (build 11.0.25+9-post-Ubuntu-1ubuntu122.04, mixed mode, sharing)\n",
      "  Starting server from /home/ritwikgoel/.local/lib/python3.10/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpafx4bugi\n",
      "  JVM stdout: /tmp/tmpafx4bugi/h2o_ritwikgoel_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpafx4bugi/h2o_ritwikgoel_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.6</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>26 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_ritwikgoel_i8cm4o</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>15.64 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.12 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------\n",
       "H2O_cluster_uptime:         01 secs\n",
       "H2O_cluster_timezone:       America/New_York\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.6\n",
       "H2O_cluster_version_age:    26 days\n",
       "H2O_cluster_name:           H2O_from_python_ritwikgoel_i8cm4o\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    15.64 Gb\n",
       "H2O_cluster_total_cores:    16\n",
       "H2O_cluster_allowed_cores:  16\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.12 final\n",
       "--------------------------  ---------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "\n",
    "# Initialize H2O environment\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb6493e4-32f1-4741-9a5d-d5417b422e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Training data in H2O:\n",
      "\n",
      "Testing data in H2O:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  AP001</th><th style=\"text-align: right;\">  AP002</th><th style=\"text-align: right;\">  AP003</th><th style=\"text-align: right;\">  AP004</th><th>AP005              </th><th>AP006  </th><th style=\"text-align: right;\">  AP007</th><th style=\"text-align: right;\">  AP008</th><th style=\"text-align: right;\">  AP009</th><th style=\"text-align: right;\">  TD001</th><th style=\"text-align: right;\">  TD002</th><th style=\"text-align: right;\">  TD005</th><th style=\"text-align: right;\">  TD006</th><th style=\"text-align: right;\">  TD009</th><th style=\"text-align: right;\">  TD010</th><th style=\"text-align: right;\">  TD013</th><th style=\"text-align: right;\">  TD014</th><th style=\"text-align: right;\">  TD015</th><th style=\"text-align: right;\">  TD022</th><th style=\"text-align: right;\">  TD023</th><th style=\"text-align: right;\">  TD024</th><th style=\"text-align: right;\">  CR004</th><th style=\"text-align: right;\">  CR005</th><th style=\"text-align: right;\">  CR009</th><th style=\"text-align: right;\">  CR015</th><th style=\"text-align: right;\">  CR017</th><th style=\"text-align: right;\">  CR018</th><th style=\"text-align: right;\">  CR019</th><th style=\"text-align: right;\">  PA022</th><th style=\"text-align: right;\">  PA023</th><th style=\"text-align: right;\">  PA028</th><th style=\"text-align: right;\">  PA029</th><th style=\"text-align: right;\">  PA030</th><th style=\"text-align: right;\">  PA031</th><th style=\"text-align: right;\">  CD008</th><th style=\"text-align: right;\">  CD018</th><th style=\"text-align: right;\">  CD071</th><th style=\"text-align: right;\">  CD072</th><th style=\"text-align: right;\">  CD088</th><th style=\"text-align: right;\">  CD100</th><th style=\"text-align: right;\">  CD101</th><th style=\"text-align: right;\">  CD106</th><th style=\"text-align: right;\">  CD107</th><th style=\"text-align: right;\">  CD108</th><th style=\"text-align: right;\">  CD113</th><th style=\"text-align: right;\">  CD114</th><th style=\"text-align: right;\">  CD115</th><th style=\"text-align: right;\">  CD117</th><th style=\"text-align: right;\">  CD118</th><th style=\"text-align: right;\">  CD120</th><th style=\"text-align: right;\">  CD121</th><th style=\"text-align: right;\">  CD123</th><th style=\"text-align: right;\">  CD130</th><th style=\"text-align: right;\">  CD131</th><th style=\"text-align: right;\">  CD132</th><th style=\"text-align: right;\">  CD133</th><th style=\"text-align: right;\">  CD135</th><th style=\"text-align: right;\">  CD136</th><th style=\"text-align: right;\">  CD137</th><th style=\"text-align: right;\">  CD152</th><th style=\"text-align: right;\">  CD153</th><th style=\"text-align: right;\">  CD160</th><th style=\"text-align: right;\">  CD162</th><th style=\"text-align: right;\">  CD164</th><th style=\"text-align: right;\">  CD166</th><th style=\"text-align: right;\">  CD167</th><th style=\"text-align: right;\">  CD169</th><th style=\"text-align: right;\">  CD170</th><th style=\"text-align: right;\">  CD172</th><th style=\"text-align: right;\">  CD173</th><th style=\"text-align: right;\">  MB005</th><th>MB007  </th><th style=\"text-align: right;\">  loan_default</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">     26</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">     12</td><td>2017-05-27 18:56:00</td><td>ios    </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">  70800</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">     -1</td><td style=\"text-align: right;\">     -1</td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">    -98</td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">    903</td><td style=\"text-align: right;\">    380</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">     14</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     69</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">    111</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">    138</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">     45</td><td style=\"text-align: right;\">     21</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     11</td><td style=\"text-align: right;\">     49</td><td style=\"text-align: right;\">   1800</td><td style=\"text-align: right;\">   1711</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">     14</td><td style=\"text-align: right;\">     14</td><td style=\"text-align: right;\">    216</td><td style=\"text-align: right;\">    216</td><td style=\"text-align: right;\">   1187</td><td style=\"text-align: right;\">   1187</td><td style=\"text-align: right;\">   2428</td><td style=\"text-align: right;\">   2428</td><td style=\"text-align: right;\">      4</td><td>IPHONE7</td><td style=\"text-align: right;\">             0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     34</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">     12</td><td>2017-06-03 13:01:00</td><td>h5     </td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">  73360</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">     -1</td><td style=\"text-align: right;\">     -1</td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">    -98</td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">  14830</td><td style=\"text-align: right;\">    283</td><td style=\"text-align: right;\">     30</td><td style=\"text-align: right;\">     12</td><td style=\"text-align: right;\">     48</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     59</td><td style=\"text-align: right;\">     46</td><td style=\"text-align: right;\">     91</td><td style=\"text-align: right;\">     69</td><td style=\"text-align: right;\">    117</td><td style=\"text-align: right;\">     96</td><td style=\"text-align: right;\">    135</td><td style=\"text-align: right;\">     52</td><td style=\"text-align: right;\">     64</td><td style=\"text-align: right;\">    148</td><td style=\"text-align: right;\">    224</td><td style=\"text-align: right;\">     62</td><td style=\"text-align: right;\">    105</td><td style=\"text-align: right;\">   4451</td><td style=\"text-align: right;\">  13786</td><td style=\"text-align: right;\">     14</td><td style=\"text-align: right;\">     28</td><td style=\"text-align: right;\">     24</td><td style=\"text-align: right;\">    935</td><td style=\"text-align: right;\">    935</td><td style=\"text-align: right;\">   1633</td><td style=\"text-align: right;\">   1542</td><td style=\"text-align: right;\">   3620</td><td style=\"text-align: right;\">   3414</td><td style=\"text-align: right;\">     11</td><td>WEB    </td><td style=\"text-align: right;\">             1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     29</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">     12</td><td>2017-05-19 15:33:00</td><td>h5     </td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">   9500</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">     -1</td><td style=\"text-align: right;\">     -1</td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">    -98</td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">  17513</td><td style=\"text-align: right;\">    590</td><td style=\"text-align: right;\">    158</td><td style=\"text-align: right;\">     68</td><td style=\"text-align: right;\">     57</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     93</td><td style=\"text-align: right;\">     73</td><td style=\"text-align: right;\">    189</td><td style=\"text-align: right;\">    150</td><td style=\"text-align: right;\">    310</td><td style=\"text-align: right;\">    245</td><td style=\"text-align: right;\">    187</td><td style=\"text-align: right;\">    102</td><td style=\"text-align: right;\">    102</td><td style=\"text-align: right;\">    187</td><td style=\"text-align: right;\">    324</td><td style=\"text-align: right;\">    167</td><td style=\"text-align: right;\">    167</td><td style=\"text-align: right;\">  17210</td><td style=\"text-align: right;\">  35051</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">    141</td><td style=\"text-align: right;\">    141</td><td style=\"text-align: right;\">    141</td><td style=\"text-align: right;\">    141</td><td style=\"text-align: right;\">    166</td><td style=\"text-align: right;\">    166</td><td style=\"text-align: right;\">      7</td><td>WEB    </td><td style=\"text-align: right;\">             0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     31</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">     12</td><td>2017-06-16 19:33:00</td><td>h5     </td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     25</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">   5198</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">     11</td><td style=\"text-align: right;\">     -1</td><td style=\"text-align: right;\">     -1</td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">    -98</td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">   7455</td><td style=\"text-align: right;\">    285</td><td style=\"text-align: right;\">     77</td><td style=\"text-align: right;\">     98</td><td style=\"text-align: right;\">     42</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     16</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">     78</td><td style=\"text-align: right;\">     58</td><td style=\"text-align: right;\">    108</td><td style=\"text-align: right;\">     82</td><td style=\"text-align: right;\">    147</td><td style=\"text-align: right;\">    113</td><td style=\"text-align: right;\">     86</td><td style=\"text-align: right;\">    113</td><td style=\"text-align: right;\">    116</td><td style=\"text-align: right;\">     96</td><td style=\"text-align: right;\">    131</td><td style=\"text-align: right;\">    128</td><td style=\"text-align: right;\">    134</td><td style=\"text-align: right;\">   8622</td><td style=\"text-align: right;\">  12388</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">    145</td><td style=\"text-align: right;\">    145</td><td style=\"text-align: right;\">     10</td><td>WEB    </td><td style=\"text-align: right;\">             0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     44</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">     12</td><td>2017-05-04 15:38:00</td><td>h5     </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     30</td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\"> 152500</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">     11</td><td style=\"text-align: right;\">     47</td><td style=\"text-align: right;\">     -1</td><td style=\"text-align: right;\">163    </td><td style=\"text-align: right;\">163    </td><td style=\"text-align: right;\">    -98</td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">  20293</td><td style=\"text-align: right;\">    496</td><td style=\"text-align: right;\">     46</td><td style=\"text-align: right;\">     23</td><td style=\"text-align: right;\">     91</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">     99</td><td style=\"text-align: right;\">     68</td><td style=\"text-align: right;\">    185</td><td style=\"text-align: right;\">    123</td><td style=\"text-align: right;\">    222</td><td style=\"text-align: right;\">    160</td><td style=\"text-align: right;\">     88</td><td style=\"text-align: right;\">     70</td><td style=\"text-align: right;\">     74</td><td style=\"text-align: right;\">    112</td><td style=\"text-align: right;\">    119</td><td style=\"text-align: right;\">     79</td><td style=\"text-align: right;\">     90</td><td style=\"text-align: right;\">   9288</td><td style=\"text-align: right;\">  10913</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">     12</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">   4359</td><td style=\"text-align: right;\">    600</td><td style=\"text-align: right;\">   4359</td><td style=\"text-align: right;\">    600</td><td style=\"text-align: right;\">   4904</td><td style=\"text-align: right;\">   1104</td><td style=\"text-align: right;\">     13</td><td>WEB    </td><td style=\"text-align: right;\">             1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     48</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      6</td><td>2017-06-20 09:34:00</td><td>h5     </td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">     12</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">     16</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">     23</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">     30</td><td style=\"text-align: right;\">     27</td><td style=\"text-align: right;\">     16</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">  56344</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">    103</td><td style=\"text-align: right;\">    103</td><td style=\"text-align: right;\">164.889</td><td style=\"text-align: right;\">164.889</td><td style=\"text-align: right;\">    -98</td><td style=\"text-align: right;\">164.889</td><td style=\"text-align: right;\">  14273</td><td style=\"text-align: right;\">    270</td><td style=\"text-align: right;\">     17</td><td style=\"text-align: right;\">     56</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     63</td><td style=\"text-align: right;\">     47</td><td style=\"text-align: right;\">     94</td><td style=\"text-align: right;\">     70</td><td style=\"text-align: right;\">    126</td><td style=\"text-align: right;\">     98</td><td style=\"text-align: right;\">     63</td><td style=\"text-align: right;\">     91</td><td style=\"text-align: right;\">    125</td><td style=\"text-align: right;\">     66</td><td style=\"text-align: right;\">     83</td><td style=\"text-align: right;\">    138</td><td style=\"text-align: right;\">    169</td><td style=\"text-align: right;\">  29947</td><td style=\"text-align: right;\">   9928</td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">     14</td><td style=\"text-align: right;\">     14</td><td style=\"text-align: right;\">    686</td><td style=\"text-align: right;\">    686</td><td style=\"text-align: right;\">   1546</td><td style=\"text-align: right;\">   1546</td><td style=\"text-align: right;\">   2374</td><td style=\"text-align: right;\">   2374</td><td style=\"text-align: right;\">     11</td><td>WEB    </td><td style=\"text-align: right;\">             1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     21</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">     12</td><td>2017-06-10 12:45:00</td><td>h5     </td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">  10000</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">     -1</td><td style=\"text-align: right;\">     -1</td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">    -98</td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">  25269</td><td style=\"text-align: right;\">    318</td><td style=\"text-align: right;\">     15</td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     12</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">     38</td><td style=\"text-align: right;\">     30</td><td style=\"text-align: right;\">     56</td><td style=\"text-align: right;\">     47</td><td style=\"text-align: right;\">     75</td><td style=\"text-align: right;\">     65</td><td style=\"text-align: right;\">    200</td><td style=\"text-align: right;\">    131</td><td style=\"text-align: right;\">    131</td><td style=\"text-align: right;\">    206</td><td style=\"text-align: right;\">    295</td><td style=\"text-align: right;\">    189</td><td style=\"text-align: right;\">    189</td><td style=\"text-align: right;\">  21809</td><td style=\"text-align: right;\">  61691</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     50</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">    223</td><td style=\"text-align: right;\">    173</td><td style=\"text-align: right;\">      3</td><td>WEB    </td><td style=\"text-align: right;\">             0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     30</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">     12</td><td>2017-04-13 14:56:00</td><td>h5     </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">     12</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">     14</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">     15</td><td style=\"text-align: right;\">     18</td><td style=\"text-align: right;\">     16</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">   8535</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">     87</td><td style=\"text-align: right;\">     -1</td><td style=\"text-align: right;\">174    </td><td style=\"text-align: right;\">174    </td><td style=\"text-align: right;\">    -98</td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">  14448</td><td style=\"text-align: right;\">    321</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">     20</td><td style=\"text-align: right;\">     15</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">     15</td><td style=\"text-align: right;\">     53</td><td style=\"text-align: right;\">     46</td><td style=\"text-align: right;\">     94</td><td style=\"text-align: right;\">     80</td><td style=\"text-align: right;\">    123</td><td style=\"text-align: right;\">    101</td><td style=\"text-align: right;\">    128</td><td style=\"text-align: right;\">     46</td><td style=\"text-align: right;\">     63</td><td style=\"text-align: right;\">    135</td><td style=\"text-align: right;\">    211</td><td style=\"text-align: right;\">     75</td><td style=\"text-align: right;\">    102</td><td style=\"text-align: right;\">   5207</td><td style=\"text-align: right;\">  12377</td><td style=\"text-align: right;\">     12</td><td style=\"text-align: right;\">     38</td><td style=\"text-align: right;\">     22</td><td style=\"text-align: right;\">   1620</td><td style=\"text-align: right;\">    598</td><td style=\"text-align: right;\">   2436</td><td style=\"text-align: right;\">   1359</td><td style=\"text-align: right;\">   4369</td><td style=\"text-align: right;\">   3104</td><td style=\"text-align: right;\">      3</td><td>WEB    </td><td style=\"text-align: right;\">             1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     33</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">     12</td><td>2017-06-06 16:33:00</td><td>ios    </td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">     15</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\"> 473000</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">     12</td><td style=\"text-align: right;\">     -1</td><td style=\"text-align: right;\">     -1</td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">    -98</td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">  24136</td><td style=\"text-align: right;\">    638</td><td style=\"text-align: right;\">     32</td><td style=\"text-align: right;\">     30</td><td style=\"text-align: right;\">     68</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">     86</td><td style=\"text-align: right;\">     55</td><td style=\"text-align: right;\">    150</td><td style=\"text-align: right;\">     97</td><td style=\"text-align: right;\">    193</td><td style=\"text-align: right;\">    124</td><td style=\"text-align: right;\">     94</td><td style=\"text-align: right;\">     99</td><td style=\"text-align: right;\">    107</td><td style=\"text-align: right;\">    119</td><td style=\"text-align: right;\">    113</td><td style=\"text-align: right;\">    117</td><td style=\"text-align: right;\">    133</td><td style=\"text-align: right;\">  14488</td><td style=\"text-align: right;\">  21187</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">     22</td><td style=\"text-align: right;\">     21</td><td style=\"text-align: right;\">    381</td><td style=\"text-align: right;\">    296</td><td style=\"text-align: right;\">   1124</td><td style=\"text-align: right;\">   1039</td><td style=\"text-align: right;\">   2966</td><td style=\"text-align: right;\">   2881</td><td style=\"text-align: right;\">      7</td><td>IPHONE7</td><td style=\"text-align: right;\">             0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">     30</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">     12</td><td>2017-06-29 15:19:00</td><td>android</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">    nan</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">     -1</td><td style=\"text-align: right;\">     -1</td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">    -98</td><td style=\"text-align: right;\">-98    </td><td style=\"text-align: right;\">   3326</td><td style=\"text-align: right;\">    231</td><td style=\"text-align: right;\">     28</td><td style=\"text-align: right;\">     40</td><td style=\"text-align: right;\">     56</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">     24</td><td style=\"text-align: right;\">     16</td><td style=\"text-align: right;\">     55</td><td style=\"text-align: right;\">     41</td><td style=\"text-align: right;\">     75</td><td style=\"text-align: right;\">     58</td><td style=\"text-align: right;\">     87</td><td style=\"text-align: right;\">     78</td><td style=\"text-align: right;\">     78</td><td style=\"text-align: right;\">     87</td><td style=\"text-align: right;\">    123</td><td style=\"text-align: right;\">    124</td><td style=\"text-align: right;\">    124</td><td style=\"text-align: right;\">   6013</td><td style=\"text-align: right;\">   5734</td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">     13</td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">    621</td><td style=\"text-align: right;\">    621</td><td style=\"text-align: right;\">    922</td><td style=\"text-align: right;\">    753</td><td style=\"text-align: right;\">   2338</td><td style=\"text-align: right;\">    753</td><td style=\"text-align: right;\">      6</td><td>OPPO   </td><td style=\"text-align: right;\">             0</td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 73 columns]</pre>"
      ],
      "text/plain": [
       "  AP001    AP002    AP003    AP004  AP005                AP006      AP007    AP008    AP009    TD001    TD002    TD005    TD006    TD009    TD010    TD013    TD014    TD015    TD022    TD023    TD024    CR004    CR005    CR009    CR015    CR017    CR018    CR019    PA022    PA023    PA028    PA029    PA030    PA031    CD008    CD018    CD071    CD072    CD088    CD100    CD101    CD106    CD107    CD108    CD113    CD114    CD115    CD117    CD118    CD120    CD121    CD123    CD130    CD131    CD132    CD133    CD135    CD136    CD137    CD152    CD153    CD160    CD162    CD164    CD166    CD167    CD169    CD170    CD172    CD173    MB005  MB007      loan_default\n",
       "-------  -------  -------  -------  -------------------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  -------  --------------\n",
       "     26        1        3       12  2017-05-27 18:56:00  ios            5        5        1        0        0        2        0        4        0        4        0        0      nan        3        4        2        1    70800        5        2        2        3       -1       -1  -98      -98          -98  -98          903      380        0        7       14        0        0        0        0        0        0        0       69        3      111        5      138        6        0        9       45       21        0       11       49     1800     1711        7       14       14      216      216     1187     1187     2428     2428        4  IPHONE7               0\n",
       "     34        2        1       12  2017-06-03 13:01:00  h5             4        4        1        1        1        2        1        7        1        9        3        1       10        6       10        3        1    73360        5        6        5        4       -1       -1  -98      -98          -98  -98        14830      283       30       12       48        0        0        0        0        0        0        0       59       46       91       69      117       96      135       52       64      148      224       62      105     4451    13786       14       28       24      935      935     1633     1542     3620     3414       11  WEB                   1\n",
       "     29        1        1       12  2017-05-19 15:33:00  h5             4        3        0        0        0        0        0        0        0        0        0        0      nan      nan      nan        1        1     9500        5        7        6        8       -1       -1  -98      -98          -98  -98        17513      590      158       68       57        0        0        0        0        0        0        0       93       73      189      150      310      245      187      102      102      187      324      167      167    17210    35051        1        2        2      141      141      141      141      166      166        7  WEB                   0\n",
       "     31        2        1       12  2017-06-16 19:33:00  h5             3        3        1        4        1        4        1        7        2        9        2        0       25        0        8        1        1     5198        4        7        5       11       -1       -1  -98      -98          -98  -98         7455      285       77       98       42        3        0       16        8        8        2        7       78       58      108       82      147      113       86      113      116       96      131      128      134     8622    12388        0        3        3        0        0        0        0      145      145       10  WEB                   0\n",
       "     44        1        1       12  2017-05-04 15:38:00  h5             2        2        1        4        2        6        3        8        3        7        3        0       30        9        4        3        3   152500        5        7        7       11       47       -1  163      163          -98  -98        20293      496       46       23       91        6        4        6        4        2        2        2       99       68      185      123      222      160       88       70       74      112      119       79       90     9288    10913        6       12        8     4359      600     4359      600     4904     1104       13  WEB                   1\n",
       "     48        1        1        6  2017-06-20 09:34:00  h5             4        4        1        6        1       12        3       16        6       23        7        3       30       27       16        2        1    56344        5        7        4        4      103      103  164.889  164.889      -98  164.889    14273      270       17       56        2        0        0        0        0        0        0        0       63       47       94       70      126       98       63       91      125       66       83      138      169    29947     9928        9       14       14      686      686     1546     1546     2374     2374       11  WEB                   1\n",
       "     21        2        3       12  2017-06-10 12:45:00  h5             3        3        1        3        1        6        1        7        1        9        1        1       20        9        4        1        1    10000        2        3        1        2       -1       -1  -98      -98          -98  -98        25269      318       15       10        2        1        0       12        6        6        1        2       38       30       56       47       75       65      200      131      131      206      295      189      189    21809    61691        0        2        1       50        0       50        0      223      173        3  WEB                   0\n",
       "     30        1        1       12  2017-04-13 14:56:00  h5             5        3        0        3        0        7        2       12        5       14        5        1       15       18       16        3        1     8535        5        2        1        2       87       -1  174      174          -98  -98        14448      321        0        0        0        6        5       20       15        5        5       15       53       46       94       80      123      101      128       46       63      135      211       75      102     5207    12377       12       38       22     1620      598     2436     1359     4369     3104        3  WEB                   1\n",
       "     33        1        4       12  2017-06-06 16:33:00  ios            4        4        1        2        0        2        2        4        3        5        3        2       15        6        8        4        1   473000        6        8        8       12       -1       -1  -98      -98          -98  -98        24136      638       32       30       68        2        1        2        1        1        1        1       86       55      150       97      193      124       94       99      107      119      113      117      133    14488    21187        6       22       21      381      296     1124     1039     2966     2881        7  IPHONE7               0\n",
       "     30        2        3       12  2017-06-29 15:19:00  android        4        4        1        0        0        0        0        0        0        1        0        1      nan      nan      nan        3        1        0        5        5        1        9       -1       -1  -98      -98          -98  -98         3326      231       28       40       56        1        0        1        0        1        1        1       24       16       55       41       75       58       87       78       78       87      123      124      124     6013     5734       10       13       10      621      621      922      753     2338      753        6  OPPO                  0\n",
       "[10 rows x 73 columns]\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert splits to H2OFrames\n",
    "train_hf = h2o.H2OFrame(pd.DataFrame(X_train, columns=X.columns).assign(loan_default=y_train.values))\n",
    "test_hf = h2o.H2OFrame(pd.DataFrame(X_test, columns=X.columns).assign(loan_default=y_test.values))\n",
    "\n",
    "# Ensure the target column is categorical\n",
    "train_hf['loan_default'] = train_hf['loan_default'].asfactor()\n",
    "test_hf['loan_default'] = test_hf['loan_default'].asfactor()\n",
    "\n",
    "# Confirm data upload\n",
    "print(\"Training data in H2O:\")\n",
    "train_hf.head()\n",
    "print(\"\\nTesting data in H2O:\")\n",
    "train_hf.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caa007c-ba57-456f-876b-d9fc82cef96a",
   "metadata": {},
   "source": [
    "## Generalized Linear Model (GLM): Baseline and Hyperparameter Tuning\n",
    "\n",
    "We start by building a **baseline GLM model** as a reference point. The baseline model is configured with a reasonable set of hyperparameters to ensure a robust starting point. This provides a foundation for comparison when fine-tuning the model using grid search.\n",
    "\n",
    "Key hyperparameters included in the baseline model are:\n",
    "- **`family`**: Specifies the type of model. We use `binomial` for binary classification.\n",
    "- **`alpha`**: Controls the balance between L1 (Lasso) and L2 (Ridge) regularization. Default value of `0.5` is used initially.\n",
    "- **`lambda`**: Regularization strength to prevent overfitting. A moderate value is set.\n",
    "- **`balance_classes`**: Ensures the class distribution is balanced during training.\n",
    "- **`missing_values_handling`**: Missing values (`NaN`) are handled using H2O's default mechanism.\n",
    "\n",
    "Once the baseline model is evaluated, we will proceed with **grid search** to explore different combinations of `alpha`, `lambda`, and other relevant hyperparameters to improve model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b562a2a3-87ff-4607-8559-21f69819dcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2OGeneralizedLinearEstimator : Generalized Linear Modeling\n",
       "Model Key: GLM_model_python_1732816896406_1\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>GLM Model: summary</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>family</th>\n",
       "<th>link</th>\n",
       "<th>regularization</th>\n",
       "<th>lambda_search</th>\n",
       "<th>number_of_predictors_total</th>\n",
       "<th>number_of_active_predictors</th>\n",
       "<th>number_of_iterations</th>\n",
       "<th>training_frame</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>binomial</td>\n",
       "<td>logit</td>\n",
       "<td>Elastic Net (alpha = 0.05, lambda = 0.001516 )</td>\n",
       "<td>nlambda = 100, lambda.max = 1.1201, lambda.min = 0.001516, lambda.1se = -1.0</td>\n",
       "<td>177</td>\n",
       "<td>84</td>\n",
       "<td>87</td>\n",
       "<td>py_1_sid_a941</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomialGLM: glm\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.14415154273649558\n",
       "RMSE: 0.3796729418018824\n",
       "LogLoss: 0.452508067339041\n",
       "AUC: 0.6979300197873822\n",
       "AUCPR: 0.34388163863416327\n",
       "Gini: 0.39586003957476446\n",
       "Null degrees of freedom: 63999\n",
       "Residual degrees of freedom: 63915\n",
       "Null deviance: 62898.19904002497\n",
       "Residual deviance: 57921.03261939725\n",
       "AIC: 58091.03261939725</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-3.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-3 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-3 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-3 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table th,\n",
       "#h2o-table-3 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2078785027665441</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>34705.0</td>\n",
       "<td>16905.0</td>\n",
       "<td>0.3276</td>\n",
       "<td> (16905.0/51610.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>4752.0</td>\n",
       "<td>7638.0</td>\n",
       "<td>0.3835</td>\n",
       "<td> (4752.0/12390.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>39457.0</td>\n",
       "<td>24543.0</td>\n",
       "<td>0.3384</td>\n",
       "<td> (21657.0/64000.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.2078785</td>\n",
       "<td>0.4136138</td>\n",
       "<td>224.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1239897</td>\n",
       "<td>0.5779263</td>\n",
       "<td>306.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.2910599</td>\n",
       "<td>0.3704243</td>\n",
       "<td>156.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5867059</td>\n",
       "<td>0.8070781</td>\n",
       "<td>29.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9361920</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0046020</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9361920</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2078785</td>\n",
       "<td>0.2347699</td>\n",
       "<td>224.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2003406</td>\n",
       "<td>0.6447942</td>\n",
       "<td>231.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1928505</td>\n",
       "<td>0.6466178</td>\n",
       "<td>238.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9361920</td>\n",
       "<td>51610.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9361920</td>\n",
       "<td>12389.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0046020</td>\n",
       "<td>51610.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0046020</td>\n",
       "<td>12390.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9361920</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9361920</td>\n",
       "<td>0.9999193</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0046020</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0046020</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-5.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-5 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-5 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-5 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table th,\n",
       "#h2o-table-5 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 19.36 %, avg score: 19.36 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.01</td>\n",
       "<td>0.5310911</td>\n",
       "<td>2.6957224</td>\n",
       "<td>2.6957224</td>\n",
       "<td>0.521875</td>\n",
       "<td>0.6015978</td>\n",
       "<td>0.521875</td>\n",
       "<td>0.6015978</td>\n",
       "<td>0.0269572</td>\n",
       "<td>0.0269572</td>\n",
       "<td>169.5722357</td>\n",
       "<td>169.5722357</td>\n",
       "<td>0.0210281</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.02</td>\n",
       "<td>0.4758254</td>\n",
       "<td>2.3486683</td>\n",
       "<td>2.5221953</td>\n",
       "<td>0.4546875</td>\n",
       "<td>0.5011366</td>\n",
       "<td>0.4882812</td>\n",
       "<td>0.5513672</td>\n",
       "<td>0.0234867</td>\n",
       "<td>0.0504439</td>\n",
       "<td>134.8668281</td>\n",
       "<td>152.2195319</td>\n",
       "<td>0.0377526</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.03</td>\n",
       "<td>0.4422127</td>\n",
       "<td>2.3648103</td>\n",
       "<td>2.4697337</td>\n",
       "<td>0.4578125</td>\n",
       "<td>0.4578630</td>\n",
       "<td>0.478125</td>\n",
       "<td>0.5201991</td>\n",
       "<td>0.0236481</td>\n",
       "<td>0.0740920</td>\n",
       "<td>136.4810331</td>\n",
       "<td>146.9733656</td>\n",
       "<td>0.0546772</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.4165657</td>\n",
       "<td>2.1226796</td>\n",
       "<td>2.3829701</td>\n",
       "<td>0.4109375</td>\n",
       "<td>0.4289151</td>\n",
       "<td>0.4613281</td>\n",
       "<td>0.4973781</td>\n",
       "<td>0.0212268</td>\n",
       "<td>0.0953188</td>\n",
       "<td>112.2679580</td>\n",
       "<td>138.2970137</td>\n",
       "<td>0.0685992</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.3976169</td>\n",
       "<td>2.0096852</td>\n",
       "<td>2.3083132</td>\n",
       "<td>0.3890625</td>\n",
       "<td>0.4068149</td>\n",
       "<td>0.446875</td>\n",
       "<td>0.4792655</td>\n",
       "<td>0.0200969</td>\n",
       "<td>0.1154157</td>\n",
       "<td>100.9685230</td>\n",
       "<td>130.8313156</td>\n",
       "<td>0.0811200</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.3367177</td>\n",
       "<td>1.9225182</td>\n",
       "<td>2.1154157</td>\n",
       "<td>0.3721875</td>\n",
       "<td>0.3641324</td>\n",
       "<td>0.4095313</td>\n",
       "<td>0.4216990</td>\n",
       "<td>0.0961259</td>\n",
       "<td>0.2115416</td>\n",
       "<td>92.2518160</td>\n",
       "<td>111.5415658</td>\n",
       "<td>0.1383193</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.2998651</td>\n",
       "<td>1.7885391</td>\n",
       "<td>2.0064568</td>\n",
       "<td>0.34625</td>\n",
       "<td>0.3169699</td>\n",
       "<td>0.3884375</td>\n",
       "<td>0.3867893</td>\n",
       "<td>0.0894270</td>\n",
       "<td>0.3009685</td>\n",
       "<td>78.8539144</td>\n",
       "<td>100.6456820</td>\n",
       "<td>0.1872115</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.2735662</td>\n",
       "<td>1.5512510</td>\n",
       "<td>1.8926554</td>\n",
       "<td>0.3003125</td>\n",
       "<td>0.2860107</td>\n",
       "<td>0.3664062</td>\n",
       "<td>0.3615946</td>\n",
       "<td>0.0775626</td>\n",
       "<td>0.3785311</td>\n",
       "<td>55.1251009</td>\n",
       "<td>89.2655367</td>\n",
       "<td>0.2213910</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.2334162</td>\n",
       "<td>1.3817595</td>\n",
       "<td>1.7223567</td>\n",
       "<td>0.2675</td>\n",
       "<td>0.2522923</td>\n",
       "<td>0.3334375</td>\n",
       "<td>0.3251605</td>\n",
       "<td>0.1381759</td>\n",
       "<td>0.5167070</td>\n",
       "<td>38.1759483</td>\n",
       "<td>72.2356739</td>\n",
       "<td>0.2687318</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.2027003</td>\n",
       "<td>1.1686844</td>\n",
       "<td>1.5839387</td>\n",
       "<td>0.22625</td>\n",
       "<td>0.2177682</td>\n",
       "<td>0.3066406</td>\n",
       "<td>0.2983124</td>\n",
       "<td>0.1168684</td>\n",
       "<td>0.6335755</td>\n",
       "<td>16.8684423</td>\n",
       "<td>58.3938660</td>\n",
       "<td>0.2896499</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.1761044</td>\n",
       "<td>0.9499596</td>\n",
       "<td>1.4571429</td>\n",
       "<td>0.1839062</td>\n",
       "<td>0.1891230</td>\n",
       "<td>0.2820937</td>\n",
       "<td>0.2764746</td>\n",
       "<td>0.0949960</td>\n",
       "<td>0.7285714</td>\n",
       "<td>-5.0040355</td>\n",
       "<td>45.7142857</td>\n",
       "<td>0.2834445</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.1521066</td>\n",
       "<td>0.7949960</td>\n",
       "<td>1.3467850</td>\n",
       "<td>0.1539062</td>\n",
       "<td>0.1639882</td>\n",
       "<td>0.2607292</td>\n",
       "<td>0.2577268</td>\n",
       "<td>0.0794996</td>\n",
       "<td>0.8080710</td>\n",
       "<td>-20.5004036</td>\n",
       "<td>34.6785042</td>\n",
       "<td>0.2580226</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.1278584</td>\n",
       "<td>0.7207425</td>\n",
       "<td>1.2573504</td>\n",
       "<td>0.1395312</td>\n",
       "<td>0.1399679</td>\n",
       "<td>0.2434152</td>\n",
       "<td>0.2409041</td>\n",
       "<td>0.0720743</td>\n",
       "<td>0.8801453</td>\n",
       "<td>-27.9257466</td>\n",
       "<td>25.7350398</td>\n",
       "<td>0.2233927</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.1021505</td>\n",
       "<td>0.5665860</td>\n",
       "<td>1.1710048</td>\n",
       "<td>0.1096875</td>\n",
       "<td>0.1151781</td>\n",
       "<td>0.2266992</td>\n",
       "<td>0.2251884</td>\n",
       "<td>0.0566586</td>\n",
       "<td>0.9368039</td>\n",
       "<td>-43.3414044</td>\n",
       "<td>17.1004843</td>\n",
       "<td>0.1696463</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0712769</td>\n",
       "<td>0.4205004</td>\n",
       "<td>1.0876155</td>\n",
       "<td>0.0814062</td>\n",
       "<td>0.0874024</td>\n",
       "<td>0.2105556</td>\n",
       "<td>0.2098788</td>\n",
       "<td>0.0420500</td>\n",
       "<td>0.9788539</td>\n",
       "<td>-57.9499596</td>\n",
       "<td>8.7615460</td>\n",
       "<td>0.0977844</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0002506</td>\n",
       "<td>0.2114609</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0409375</td>\n",
       "<td>0.0470331</td>\n",
       "<td>0.1935938</td>\n",
       "<td>0.1935943</td>\n",
       "<td>0.0211461</td>\n",
       "<td>1.0</td>\n",
       "<td>-78.8539144</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-6.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-6 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-6 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-6 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table th,\n",
       "#h2o-table-6 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>iteration</th>\n",
       "<th>lambda</th>\n",
       "<th>predictors</th>\n",
       "<th>deviance_train</th>\n",
       "<th>alpha</th>\n",
       "<th>iterations</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2024-11-28 13:01:43</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>1</td>\n",
       "<td>.11E1</td>\n",
       "<td>1</td>\n",
       "<td>0.9827844</td>\n",
       "<td>0.05</td>\n",
       "<td>None</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-11-28 13:01:43</td>\n",
       "<td> 0.067 sec</td>\n",
       "<td>2</td>\n",
       "<td>.1E1</td>\n",
       "<td>3</td>\n",
       "<td>0.9821110</td>\n",
       "<td>0.05</td>\n",
       "<td>None</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-11-28 13:01:43</td>\n",
       "<td> 0.099 sec</td>\n",
       "<td>3</td>\n",
       "<td>.93E0</td>\n",
       "<td>4</td>\n",
       "<td>0.9811946</td>\n",
       "<td>0.05</td>\n",
       "<td>None</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-11-28 13:01:43</td>\n",
       "<td> 0.122 sec</td>\n",
       "<td>4</td>\n",
       "<td>.85E0</td>\n",
       "<td>5</td>\n",
       "<td>0.9800401</td>\n",
       "<td>0.05</td>\n",
       "<td>None</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-11-28 13:01:43</td>\n",
       "<td> 0.135 sec</td>\n",
       "<td>5</td>\n",
       "<td>.77E0</td>\n",
       "<td>7</td>\n",
       "<td>0.9786187</td>\n",
       "<td>0.05</td>\n",
       "<td>None</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-11-28 13:01:43</td>\n",
       "<td> 0.153 sec</td>\n",
       "<td>6</td>\n",
       "<td>.7E0</td>\n",
       "<td>8</td>\n",
       "<td>0.9768806</td>\n",
       "<td>0.05</td>\n",
       "<td>None</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-11-28 13:01:43</td>\n",
       "<td> 0.216 sec</td>\n",
       "<td>7</td>\n",
       "<td>.64E0</td>\n",
       "<td>8</td>\n",
       "<td>0.9748442</td>\n",
       "<td>0.05</td>\n",
       "<td>None</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-11-28 13:01:43</td>\n",
       "<td> 0.240 sec</td>\n",
       "<td>8</td>\n",
       "<td>.58E0</td>\n",
       "<td>8</td>\n",
       "<td>0.9728317</td>\n",
       "<td>0.05</td>\n",
       "<td>None</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-11-28 13:01:43</td>\n",
       "<td> 0.267 sec</td>\n",
       "<td>9</td>\n",
       "<td>.53E0</td>\n",
       "<td>9</td>\n",
       "<td>0.9708348</td>\n",
       "<td>0.05</td>\n",
       "<td>None</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-11-28 13:01:43</td>\n",
       "<td> 0.293 sec</td>\n",
       "<td>11</td>\n",
       "<td>.48E0</td>\n",
       "<td>14</td>\n",
       "<td>0.9685676</td>\n",
       "<td>0.05</td>\n",
       "<td>None</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-11-28 13:01:45</td>\n",
       "<td> 1.939 sec</td>\n",
       "<td>78</td>\n",
       "<td>.35E-2</td>\n",
       "<td>79</td>\n",
       "<td>0.9058294</td>\n",
       "<td>0.05</td>\n",
       "<td>None</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-11-28 13:01:45</td>\n",
       "<td> 1.968 sec</td>\n",
       "<td>79</td>\n",
       "<td>.32E-2</td>\n",
       "<td>79</td>\n",
       "<td>0.9057174</td>\n",
       "<td>0.05</td>\n",
       "<td>None</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-11-28 13:01:45</td>\n",
       "<td> 1.995 sec</td>\n",
       "<td>80</td>\n",
       "<td>.29E-2</td>\n",
       "<td>81</td>\n",
       "<td>0.9056083</td>\n",
       "<td>0.05</td>\n",
       "<td>None</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-11-28 13:01:45</td>\n",
       "<td> 2.021 sec</td>\n",
       "<td>81</td>\n",
       "<td>.26E-2</td>\n",
       "<td>82</td>\n",
       "<td>0.9055074</td>\n",
       "<td>0.05</td>\n",
       "<td>None</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-11-28 13:01:45</td>\n",
       "<td> 2.045 sec</td>\n",
       "<td>82</td>\n",
       "<td>.24E-2</td>\n",
       "<td>82</td>\n",
       "<td>0.9054122</td>\n",
       "<td>0.05</td>\n",
       "<td>None</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-11-28 13:01:45</td>\n",
       "<td> 2.074 sec</td>\n",
       "<td>83</td>\n",
       "<td>.22E-2</td>\n",
       "<td>83</td>\n",
       "<td>0.9053223</td>\n",
       "<td>0.05</td>\n",
       "<td>None</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-11-28 13:01:45</td>\n",
       "<td> 2.104 sec</td>\n",
       "<td>84</td>\n",
       "<td>.2E-2</td>\n",
       "<td>83</td>\n",
       "<td>0.9052377</td>\n",
       "<td>0.05</td>\n",
       "<td>None</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-11-28 13:01:45</td>\n",
       "<td> 2.128 sec</td>\n",
       "<td>85</td>\n",
       "<td>.18E-2</td>\n",
       "<td>84</td>\n",
       "<td>0.9051593</td>\n",
       "<td>0.05</td>\n",
       "<td>None</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-11-28 13:01:45</td>\n",
       "<td> 2.158 sec</td>\n",
       "<td>86</td>\n",
       "<td>.17E-2</td>\n",
       "<td>84</td>\n",
       "<td>0.9050849</td>\n",
       "<td>0.05</td>\n",
       "<td>None</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2024-11-28 13:01:45</td>\n",
       "<td> 2.192 sec</td>\n",
       "<td>87</td>\n",
       "<td>.15E-2</td>\n",
       "<td>85</td>\n",
       "<td>0.9050161</td>\n",
       "<td>0.05</td>\n",
       "<td>87</td>\n",
       "<td>0.3796729</td>\n",
       "<td>0.4525081</td>\n",
       "<td>0.0766336</td>\n",
       "<td>0.6979300</td>\n",
       "<td>0.3438816</td>\n",
       "<td>2.6957224</td>\n",
       "<td>0.3383906</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[72 rows x 16 columns]</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-7.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-7 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-7 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-7 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table th,\n",
       "#h2o-table-7 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>AP004</td>\n",
       "<td>0.4270276</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0720581</td></tr>\n",
       "<tr><td>AP003</td>\n",
       "<td>0.3567303</td>\n",
       "<td>0.8353799</td>\n",
       "<td>0.0601959</td></tr>\n",
       "<tr><td>CD114</td>\n",
       "<td>0.2698241</td>\n",
       "<td>0.6318657</td>\n",
       "<td>0.0455310</td></tr>\n",
       "<tr><td>TD013</td>\n",
       "<td>0.2226551</td>\n",
       "<td>0.5214067</td>\n",
       "<td>0.0375716</td></tr>\n",
       "<tr><td>CD117</td>\n",
       "<td>0.2129572</td>\n",
       "<td>0.4986966</td>\n",
       "<td>0.0359351</td></tr>\n",
       "<tr><td>AP006.android</td>\n",
       "<td>0.1807180</td>\n",
       "<td>0.4231998</td>\n",
       "<td>0.0304950</td></tr>\n",
       "<tr><td>MB005</td>\n",
       "<td>0.1571946</td>\n",
       "<td>0.3681134</td>\n",
       "<td>0.0265255</td></tr>\n",
       "<tr><td>MB007.GIONEE</td>\n",
       "<td>0.1556101</td>\n",
       "<td>0.3644030</td>\n",
       "<td>0.0262582</td></tr>\n",
       "<tr><td>CD108</td>\n",
       "<td>0.1478703</td>\n",
       "<td>0.3462781</td>\n",
       "<td>0.0249521</td></tr>\n",
       "<tr><td>CR015</td>\n",
       "<td>0.1384678</td>\n",
       "<td>0.3242595</td>\n",
       "<td>0.0233655</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>MB007.XIAOLAJIAO</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>MB007.YEPEN</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>MB007.YTONE_L985</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>MB007.YU-FLY</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>MB007.YUFLY</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>MB007.ZTE</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>MB007.ZUK</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>MB007.ZUOKU</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>CD088</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>CD169</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[177 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2OGeneralizedLinearEstimator : Generalized Linear Modeling\n",
       "Model Key: GLM_model_python_1732816896406_1\n",
       "\n",
       "\n",
       "GLM Model: summary\n",
       "    family    link    regularization                                  lambda_search                                                                 number_of_predictors_total    number_of_active_predictors    number_of_iterations    training_frame\n",
       "--  --------  ------  ----------------------------------------------  ----------------------------------------------------------------------------  ----------------------------  -----------------------------  ----------------------  ----------------\n",
       "    binomial  logit   Elastic Net (alpha = 0.05, lambda = 0.001516 )  nlambda = 100, lambda.max = 1.1201, lambda.min = 0.001516, lambda.1se = -1.0  177                           84                             87                      py_1_sid_a941\n",
       "\n",
       "ModelMetricsBinomialGLM: glm\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.14415154273649558\n",
       "RMSE: 0.3796729418018824\n",
       "LogLoss: 0.452508067339041\n",
       "AUC: 0.6979300197873822\n",
       "AUCPR: 0.34388163863416327\n",
       "Gini: 0.39586003957476446\n",
       "Null degrees of freedom: 63999\n",
       "Residual degrees of freedom: 63915\n",
       "Null deviance: 62898.19904002497\n",
       "Residual deviance: 57921.03261939725\n",
       "AIC: 58091.03261939725\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2078785027665441\n",
       "       0      1      Error    Rate\n",
       "-----  -----  -----  -------  -----------------\n",
       "0      34705  16905  0.3276   (16905.0/51610.0)\n",
       "1      4752   7638   0.3835   (4752.0/12390.0)\n",
       "Total  39457  24543  0.3384   (21657.0/64000.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.207879     0.413614  224\n",
       "max f2                       0.12399      0.577926  306\n",
       "max f0point5                 0.29106      0.370424  156\n",
       "max accuracy                 0.586706     0.807078  29\n",
       "max precision                0.936192     1         0\n",
       "max recall                   0.00460197   1         399\n",
       "max specificity              0.936192     1         0\n",
       "max absolute_mcc             0.207879     0.23477   224\n",
       "max min_per_class_accuracy   0.200341     0.644794  231\n",
       "max mean_per_class_accuracy  0.19285      0.646618  238\n",
       "max tns                      0.936192     51610     0\n",
       "max fns                      0.936192     12389     0\n",
       "max fps                      0.00460197   51610     399\n",
       "max tps                      0.00460197   12390     399\n",
       "max tnr                      0.936192     1         0\n",
       "max fnr                      0.936192     0.999919  0\n",
       "max fpr                      0.00460197   1         399\n",
       "max tpr                      0.00460197   1         399\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 19.36 %, avg score: 19.36 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.01                        0.531091           2.69572   2.69572            0.521875         0.601598   0.521875                    0.601598            0.0269572       0.0269572                  169.572   169.572            0.0210281\n",
       "2        0.02                        0.475825           2.34867   2.5222             0.454688         0.501137   0.488281                    0.551367            0.0234867       0.0504439                  134.867   152.22             0.0377526\n",
       "3        0.03                        0.442213           2.36481   2.46973            0.457813         0.457863   0.478125                    0.520199            0.0236481       0.074092                   136.481   146.973            0.0546772\n",
       "4        0.04                        0.416566           2.12268   2.38297            0.410938         0.428915   0.461328                    0.497378            0.0212268       0.0953188                  112.268   138.297            0.0685992\n",
       "5        0.05                        0.397617           2.00969   2.30831            0.389062         0.406815   0.446875                    0.479265            0.0200969       0.115416                   100.969   130.831            0.08112\n",
       "6        0.1                         0.336718           1.92252   2.11542            0.372188         0.364132   0.409531                    0.421699            0.0961259       0.211542                   92.2518   111.542            0.138319\n",
       "7        0.15                        0.299865           1.78854   2.00646            0.34625          0.31697    0.388437                    0.386789            0.089427        0.300969                   78.8539   100.646            0.187211\n",
       "8        0.2                         0.273566           1.55125   1.89266            0.300312         0.286011   0.366406                    0.361595            0.0775626       0.378531                   55.1251   89.2655            0.221391\n",
       "9        0.3                         0.233416           1.38176   1.72236            0.2675           0.252292   0.333437                    0.325161            0.138176        0.516707                   38.1759   72.2357            0.268732\n",
       "10       0.4                         0.2027             1.16868   1.58394            0.22625          0.217768   0.306641                    0.298312            0.116868        0.633575                   16.8684   58.3939            0.28965\n",
       "11       0.5                         0.176104           0.94996   1.45714            0.183906         0.189123   0.282094                    0.276475            0.094996        0.728571                   -5.00404  45.7143            0.283445\n",
       "12       0.6                         0.152107           0.794996  1.34679            0.153906         0.163988   0.260729                    0.257727            0.0794996       0.808071                   -20.5004  34.6785            0.258023\n",
       "13       0.7                         0.127858           0.720743  1.25735            0.139531         0.139968   0.243415                    0.240904            0.0720743       0.880145                   -27.9257  25.735             0.223393\n",
       "14       0.8                         0.102151           0.566586  1.171              0.109687         0.115178   0.226699                    0.225188            0.0566586       0.936804                   -43.3414  17.1005            0.169646\n",
       "15       0.9                         0.0712769          0.4205    1.08762            0.0814062        0.0874024  0.210556                    0.209879            0.04205         0.978854                   -57.95    8.76155            0.0977844\n",
       "16       1                           0.000250558        0.211461  1                  0.0409375        0.0470331  0.193594                    0.193594            0.0211461       1                          -78.8539  0                  0\n",
       "\n",
       "Scoring History: \n",
       "     timestamp            duration    iteration    lambda    predictors    deviance_train      alpha    iterations    training_rmse       training_logloss    training_r2         training_auc        training_pr_auc      training_lift       training_classification_error\n",
       "---  -------------------  ----------  -----------  --------  ------------  ------------------  -------  ------------  ------------------  ------------------  ------------------  ------------------  -------------------  ------------------  -------------------------------\n",
       "     2024-11-28 13:01:43  0.000 sec   1            .11E1     1             0.9827843600004421  0.05\n",
       "     2024-11-28 13:01:43  0.067 sec   2            .1E1      3             0.9821109946902307  0.05\n",
       "     2024-11-28 13:01:43  0.099 sec   3            .93E0     4             0.9811946138476543  0.05\n",
       "     2024-11-28 13:01:43  0.122 sec   4            .85E0     5             0.9800401492459286  0.05\n",
       "     2024-11-28 13:01:43  0.135 sec   5            .77E0     7             0.9786187415342806  0.05\n",
       "     2024-11-28 13:01:43  0.153 sec   6            .7E0      8             0.9768806055128814  0.05\n",
       "     2024-11-28 13:01:43  0.216 sec   7            .64E0     8             0.9748441644417921  0.05\n",
       "     2024-11-28 13:01:43  0.240 sec   8            .58E0     8             0.9728317248910183  0.05\n",
       "     2024-11-28 13:01:43  0.267 sec   9            .53E0     9             0.970834833703162   0.05\n",
       "     2024-11-28 13:01:43  0.293 sec   11           .48E0     14            0.9685676370969952  0.05\n",
       "---  ---                  ---         ---          ---       ---           ---                 ---      ---           ---                 ---                 ---                 ---                 ---                  ---                 ---\n",
       "     2024-11-28 13:01:45  1.939 sec   78           .35E-2    79            0.9058293968599118  0.05\n",
       "     2024-11-28 13:01:45  1.968 sec   79           .32E-2    79            0.9057174108126677  0.05\n",
       "     2024-11-28 13:01:45  1.995 sec   80           .29E-2    81            0.9056082851460343  0.05\n",
       "     2024-11-28 13:01:45  2.021 sec   81           .26E-2    82            0.9055074034314183  0.05\n",
       "     2024-11-28 13:01:45  2.045 sec   82           .24E-2    82            0.9054121562826463  0.05\n",
       "     2024-11-28 13:01:45  2.074 sec   83           .22E-2    83            0.9053223460816777  0.05\n",
       "     2024-11-28 13:01:45  2.104 sec   84           .2E-2     83            0.905237713728021   0.05\n",
       "     2024-11-28 13:01:45  2.128 sec   85           .18E-2    84            0.905159348653759   0.05\n",
       "     2024-11-28 13:01:45  2.158 sec   86           .17E-2    84            0.9050848703616297  0.05\n",
       "     2024-11-28 13:01:45  2.192 sec   87           .15E-2    85            0.9050161346780801  0.05     87            0.3796729418018824  0.452508067339041   0.0766335786720298  0.6979300197873822  0.34388163863416327  2.6957223567393056  0.338390625\n",
       "[72 rows x 16 columns]\n",
       "\n",
       "\n",
       "Variable Importances: \n",
       "variable          relative_importance    scaled_importance    percentage\n",
       "----------------  ---------------------  -------------------  --------------------\n",
       "AP004             0.4270276129245758     1.0                  0.07205808949351727\n",
       "AP003             0.35673028230667114    0.8353798946713055   0.06019587921130996\n",
       "CD114             0.2698240876197815     0.6318656673554257   0.045531032806178276\n",
       "TD013             0.22265507280826569    0.5214067335912359   0.03757157307163979\n",
       "CD117             0.2129572033882141     0.49869656420983693  0.03593512165394201\n",
       "AP006.android     0.18071801960468292    0.4231998450100285   0.030494972305375272\n",
       "MB005             0.1571945697069168     0.3681133607036355   0.02652554548934197\n",
       "MB007.GIONEE      0.155610129237175      0.3644029672260557   0.02625818162407836\n",
       "CD108             0.14787031710147858    0.3462781155737494   0.02495213944165975\n",
       "CR015             0.13846775889396667    0.3242594968171852   0.02336551984077561\n",
       "---               ---                    ---                  ---\n",
       "MB007.XIAOLAJIAO  0.0                    0.0                  0.0\n",
       "MB007.YEPEN       0.0                    0.0                  0.0\n",
       "MB007.YTONE_L985  0.0                    0.0                  0.0\n",
       "MB007.YU-FLY      0.0                    0.0                  0.0\n",
       "MB007.YUFLY       0.0                    0.0                  0.0\n",
       "MB007.ZTE         0.0                    0.0                  0.0\n",
       "MB007.ZUK         0.0                    0.0                  0.0\n",
       "MB007.ZUOKU       0.0                    0.0                  0.0\n",
       "CD088             0.0                    0.0                  0.0\n",
       "CD169             0.0                    0.0                  0.0\n",
       "[177 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the baseline GLM model\n",
    "baseline_glm = H2OGeneralizedLinearEstimator(\n",
    "    family=\"binomial\",  # Binary classification\n",
    "    alpha=0.05,  # tiny L1 penalty to encourage sparsity\n",
    "    lambda_search=True,  # Moderate regularization strength\n",
    "    balance_classes=True,  # Handle class imbalance\n",
    "    standardize=True,  # Standardize predictors\n",
    "    interactions=None,  # Can add specific pairs later if needed\n",
    "    missing_values_handling=\"MeanImputation\"  # Default NaN handling\n",
    ")\n",
    "\n",
    "# Train the baseline model\n",
    "baseline_glm.train(\n",
    "    y=\"loan_default\",  # Target variable\n",
    "    training_frame=train_hf\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68d93f9d-1364-48ee-8f6b-d289ebd71062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomialGLM: glm\n",
       "** Reported on test data. **\n",
       "\n",
       "MSE: 0.14325922435232985\n",
       "RMSE: 0.3784960030863336\n",
       "LogLoss: 0.45052119796614315\n",
       "AUC: 0.7009347618172209\n",
       "AUCPR: 0.35699785100877274\n",
       "Gini: 0.40186952363444184\n",
       "Null degrees of freedom: 15999\n",
       "Residual degrees of freedom: 15915\n",
       "Null deviance: 15725.976585763\n",
       "Residual deviance: 14416.678334916582\n",
       "AIC: 14586.678334916582</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-8.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-8 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-8 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-8 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table th,\n",
       "#h2o-table-8 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.20866963481700682</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>8787.0</td>\n",
       "<td>4115.0</td>\n",
       "<td>0.3189</td>\n",
       "<td> (4115.0/12902.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>1218.0</td>\n",
       "<td>1880.0</td>\n",
       "<td>0.3932</td>\n",
       "<td> (1218.0/3098.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>10005.0</td>\n",
       "<td>5995.0</td>\n",
       "<td>0.3333</td>\n",
       "<td> (5333.0/16000.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-9.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-9 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-9 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-9 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table th,\n",
       "#h2o-table-9 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.2086696</td>\n",
       "<td>0.4135049</td>\n",
       "<td>213.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1233504</td>\n",
       "<td>0.5787754</td>\n",
       "<td>302.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3069744</td>\n",
       "<td>0.3837032</td>\n",
       "<td>132.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4919491</td>\n",
       "<td>0.8085</td>\n",
       "<td>44.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.7925853</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0080243</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.7925853</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2525738</td>\n",
       "<td>0.2391395</td>\n",
       "<td>172.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1978355</td>\n",
       "<td>0.6422260</td>\n",
       "<td>224.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1911815</td>\n",
       "<td>0.6457873</td>\n",
       "<td>231.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.7925853</td>\n",
       "<td>12902.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.7925853</td>\n",
       "<td>3097.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0020065</td>\n",
       "<td>12902.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0080243</td>\n",
       "<td>3098.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.7925853</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.7925853</td>\n",
       "<td>0.9996772</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0020065</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0080243</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-10.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-10 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-10 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-10 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table th,\n",
       "#h2o-table-10 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-10 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-10\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 19.36 %, avg score: 19.16 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.01</td>\n",
       "<td>0.5193712</td>\n",
       "<td>2.8405423</td>\n",
       "<td>2.8405423</td>\n",
       "<td>0.55</td>\n",
       "<td>0.5894042</td>\n",
       "<td>0.55</td>\n",
       "<td>0.5894042</td>\n",
       "<td>0.0284054</td>\n",
       "<td>0.0284054</td>\n",
       "<td>184.0542285</td>\n",
       "<td>184.0542285</td>\n",
       "<td>0.0228249</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.02</td>\n",
       "<td>0.4609913</td>\n",
       "<td>2.7114267</td>\n",
       "<td>2.7759845</td>\n",
       "<td>0.525</td>\n",
       "<td>0.4875585</td>\n",
       "<td>0.5375</td>\n",
       "<td>0.5384814</td>\n",
       "<td>0.0271143</td>\n",
       "<td>0.0555197</td>\n",
       "<td>171.1426727</td>\n",
       "<td>177.5984506</td>\n",
       "<td>0.0440486</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.03</td>\n",
       "<td>0.4292418</td>\n",
       "<td>2.4854745</td>\n",
       "<td>2.6791478</td>\n",
       "<td>0.48125</td>\n",
       "<td>0.4428248</td>\n",
       "<td>0.51875</td>\n",
       "<td>0.5065958</td>\n",
       "<td>0.0248547</td>\n",
       "<td>0.0803744</td>\n",
       "<td>148.5474500</td>\n",
       "<td>167.9147837</td>\n",
       "<td>0.0624702</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.4097470</td>\n",
       "<td>2.3240801</td>\n",
       "<td>2.5903809</td>\n",
       "<td>0.45</td>\n",
       "<td>0.4192025</td>\n",
       "<td>0.5015625</td>\n",
       "<td>0.4847475</td>\n",
       "<td>0.0232408</td>\n",
       "<td>0.1036152</td>\n",
       "<td>132.4080052</td>\n",
       "<td>159.0380891</td>\n",
       "<td>0.0788904</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.3920384</td>\n",
       "<td>1.9367334</td>\n",
       "<td>2.4596514</td>\n",
       "<td>0.375</td>\n",
       "<td>0.4010487</td>\n",
       "<td>0.47625</td>\n",
       "<td>0.4680077</td>\n",
       "<td>0.0193673</td>\n",
       "<td>0.1229826</td>\n",
       "<td>93.6733376</td>\n",
       "<td>145.9651388</td>\n",
       "<td>0.0905070</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.3345735</td>\n",
       "<td>1.9690123</td>\n",
       "<td>2.2143318</td>\n",
       "<td>0.38125</td>\n",
       "<td>0.3595579</td>\n",
       "<td>0.42875</td>\n",
       "<td>0.4137828</td>\n",
       "<td>0.0984506</td>\n",
       "<td>0.2214332</td>\n",
       "<td>96.9012266</td>\n",
       "<td>121.4331827</td>\n",
       "<td>0.1505915</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.2979524</td>\n",
       "<td>1.8011620</td>\n",
       "<td>2.0766086</td>\n",
       "<td>0.34875</td>\n",
       "<td>0.3144874</td>\n",
       "<td>0.4020833</td>\n",
       "<td>0.3806844</td>\n",
       "<td>0.0900581</td>\n",
       "<td>0.3114913</td>\n",
       "<td>80.1162040</td>\n",
       "<td>107.6608565</td>\n",
       "<td>0.2002682</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.2717586</td>\n",
       "<td>1.5364751</td>\n",
       "<td>1.9415752</td>\n",
       "<td>0.2975</td>\n",
       "<td>0.2842737</td>\n",
       "<td>0.3759375</td>\n",
       "<td>0.3565817</td>\n",
       "<td>0.0768238</td>\n",
       "<td>0.3883150</td>\n",
       "<td>53.6475145</td>\n",
       "<td>94.1575210</td>\n",
       "<td>0.2335328</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.2314724</td>\n",
       "<td>1.2814719</td>\n",
       "<td>1.7215408</td>\n",
       "<td>0.248125</td>\n",
       "<td>0.2503723</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.3211786</td>\n",
       "<td>0.1281472</td>\n",
       "<td>0.5164622</td>\n",
       "<td>28.1471917</td>\n",
       "<td>72.1540779</td>\n",
       "<td>0.2684387</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.2014420</td>\n",
       "<td>1.1588121</td>\n",
       "<td>1.5808586</td>\n",
       "<td>0.224375</td>\n",
       "<td>0.2156025</td>\n",
       "<td>0.3060937</td>\n",
       "<td>0.2947845</td>\n",
       "<td>0.1158812</td>\n",
       "<td>0.6323434</td>\n",
       "<td>15.8812137</td>\n",
       "<td>58.0858618</td>\n",
       "<td>0.2881332</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.1747641</td>\n",
       "<td>1.0038735</td>\n",
       "<td>1.4654616</td>\n",
       "<td>0.194375</td>\n",
       "<td>0.1879210</td>\n",
       "<td>0.28375</td>\n",
       "<td>0.2734118</td>\n",
       "<td>0.1003873</td>\n",
       "<td>0.7327308</td>\n",
       "<td>0.3873467</td>\n",
       "<td>46.5461588</td>\n",
       "<td>0.2886136</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.1511309</td>\n",
       "<td>0.7682376</td>\n",
       "<td>1.3492576</td>\n",
       "<td>0.14875</td>\n",
       "<td>0.1626994</td>\n",
       "<td>0.26125</td>\n",
       "<td>0.2549598</td>\n",
       "<td>0.0768238</td>\n",
       "<td>0.8095546</td>\n",
       "<td>-23.1762427</td>\n",
       "<td>34.9257586</td>\n",
       "<td>0.2598723</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.1269677</td>\n",
       "<td>0.7069077</td>\n",
       "<td>1.2574933</td>\n",
       "<td>0.136875</td>\n",
       "<td>0.1390173</td>\n",
       "<td>0.2434821</td>\n",
       "<td>0.2383966</td>\n",
       "<td>0.0706908</td>\n",
       "<td>0.8802453</td>\n",
       "<td>-29.3092318</td>\n",
       "<td>25.7493314</td>\n",
       "<td>0.2235254</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.1014483</td>\n",
       "<td>0.5681085</td>\n",
       "<td>1.1713202</td>\n",
       "<td>0.11</td>\n",
       "<td>0.1146963</td>\n",
       "<td>0.2267969</td>\n",
       "<td>0.2229340</td>\n",
       "<td>0.0568108</td>\n",
       "<td>0.9370562</td>\n",
       "<td>-43.1891543</td>\n",
       "<td>17.1320207</td>\n",
       "<td>0.1699658</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0704259</td>\n",
       "<td>0.4099419</td>\n",
       "<td>1.0867226</td>\n",
       "<td>0.079375</td>\n",
       "<td>0.0871125</td>\n",
       "<td>0.2104167</td>\n",
       "<td>0.2078427</td>\n",
       "<td>0.0409942</td>\n",
       "<td>0.9780504</td>\n",
       "<td>-59.0058102</td>\n",
       "<td>8.6722617</td>\n",
       "<td>0.0967916</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0005989</td>\n",
       "<td>0.2194964</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0425</td>\n",
       "<td>0.0458832</td>\n",
       "<td>0.193625</td>\n",
       "<td>0.1916468</td>\n",
       "<td>0.0219496</td>\n",
       "<td>1.0</td>\n",
       "<td>-78.0503551</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>"
      ],
      "text/plain": [
       "ModelMetricsBinomialGLM: glm\n",
       "** Reported on test data. **\n",
       "\n",
       "MSE: 0.14325922435232985\n",
       "RMSE: 0.3784960030863336\n",
       "LogLoss: 0.45052119796614315\n",
       "AUC: 0.7009347618172209\n",
       "AUCPR: 0.35699785100877274\n",
       "Gini: 0.40186952363444184\n",
       "Null degrees of freedom: 15999\n",
       "Residual degrees of freedom: 15915\n",
       "Null deviance: 15725.976585763\n",
       "Residual deviance: 14416.678334916582\n",
       "AIC: 14586.678334916582\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.20866963481700682\n",
       "       0      1     Error    Rate\n",
       "-----  -----  ----  -------  ----------------\n",
       "0      8787   4115  0.3189   (4115.0/12902.0)\n",
       "1      1218   1880  0.3932   (1218.0/3098.0)\n",
       "Total  10005  5995  0.3333   (5333.0/16000.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.20867      0.413505  213\n",
       "max f2                       0.12335      0.578775  302\n",
       "max f0point5                 0.306974     0.383703  132\n",
       "max accuracy                 0.491949     0.8085    44\n",
       "max precision                0.792585     1         0\n",
       "max recall                   0.00802426   1         398\n",
       "max specificity              0.792585     1         0\n",
       "max absolute_mcc             0.252574     0.239139  172\n",
       "max min_per_class_accuracy   0.197836     0.642226  224\n",
       "max mean_per_class_accuracy  0.191182     0.645787  231\n",
       "max tns                      0.792585     12902     0\n",
       "max fns                      0.792585     3097      0\n",
       "max fps                      0.00200648   12902     399\n",
       "max tps                      0.00802426   3098      398\n",
       "max tnr                      0.792585     1         0\n",
       "max fnr                      0.792585     0.999677  0\n",
       "max fpr                      0.00200648   1         399\n",
       "max tpr                      0.00802426   1         398\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 19.36 %, avg score: 19.16 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.01                        0.519371           2.84054   2.84054            0.55             0.589404   0.55                        0.589404            0.0284054       0.0284054                  184.054   184.054            0.0228249\n",
       "2        0.02                        0.460991           2.71143   2.77598            0.525            0.487559   0.5375                      0.538481            0.0271143       0.0555197                  171.143   177.598            0.0440486\n",
       "3        0.03                        0.429242           2.48547   2.67915            0.48125          0.442825   0.51875                     0.506596            0.0248547       0.0803744                  148.547   167.915            0.0624702\n",
       "4        0.04                        0.409747           2.32408   2.59038            0.45             0.419202   0.501563                    0.484748            0.0232408       0.103615                   132.408   159.038            0.0788904\n",
       "5        0.05                        0.392038           1.93673   2.45965            0.375            0.401049   0.47625                     0.468008            0.0193673       0.122983                   93.6733   145.965            0.090507\n",
       "6        0.1                         0.334573           1.96901   2.21433            0.38125          0.359558   0.42875                     0.413783            0.0984506       0.221433                   96.9012   121.433            0.150591\n",
       "7        0.15                        0.297952           1.80116   2.07661            0.34875          0.314487   0.402083                    0.380684            0.0900581       0.311491                   80.1162   107.661            0.200268\n",
       "8        0.2                         0.271759           1.53648   1.94158            0.2975           0.284274   0.375937                    0.356582            0.0768238       0.388315                   53.6475   94.1575            0.233533\n",
       "9        0.3                         0.231472           1.28147   1.72154            0.248125         0.250372   0.333333                    0.321179            0.128147        0.516462                   28.1472   72.1541            0.268439\n",
       "10       0.4                         0.201442           1.15881   1.58086            0.224375         0.215602   0.306094                    0.294785            0.115881        0.632343                   15.8812   58.0859            0.288133\n",
       "11       0.5                         0.174764           1.00387   1.46546            0.194375         0.187921   0.28375                     0.273412            0.100387        0.732731                   0.387347  46.5462            0.288614\n",
       "12       0.6                         0.151131           0.768238  1.34926            0.14875          0.162699   0.26125                     0.25496             0.0768238       0.809555                   -23.1762  34.9258            0.259872\n",
       "13       0.7                         0.126968           0.706908  1.25749            0.136875         0.139017   0.243482                    0.238397            0.0706908       0.880245                   -29.3092  25.7493            0.223525\n",
       "14       0.8                         0.101448           0.568108  1.17132            0.11             0.114696   0.226797                    0.222934            0.0568108       0.937056                   -43.1892  17.132             0.169966\n",
       "15       0.9                         0.0704259          0.409942  1.08672            0.079375         0.0871125  0.210417                    0.207843            0.0409942       0.97805                    -59.0058  8.67226            0.0967916\n",
       "16       1                           0.000598933        0.219496  1                  0.0425           0.0458832  0.193625                    0.191647            0.0219496       1                          -78.0504  0                  0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate performance on the test set\n",
    "baseline_glm.model_performance(test_hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157003d9-f8fe-4bdc-b509-f7b994330908",
   "metadata": {},
   "source": [
    "## Implementing Grid Search for GLM Model\n",
    "\n",
    "To enhance the performance of our GLM model, we are implementing a grid search to systematically explore different hyperparameter combinations. The goal is to identify the optimal set of parameters that maximize model performance, specifically focusing on metrics such as **AUC** and **AUCPR**.\n",
    "\n",
    "### Approach:\n",
    "1. **Hyperparameters to Tune**:\n",
    "    - **`alpha`**: This parameter controls the balance between L1 (lasso) and L2 (ridge) regularization. By testing a range of values from `0.0` (pure ridge) to `1.0` (pure lasso), we aim to identify the best mix for our data.\n",
    "    - **`missing_values_handling`**: Options include:\n",
    "        - `\"MeanImputation\"`: Impute missing values with the mean of the column.\n",
    "        - `\"Skip\"`: Skip rows with missing values during training.\n",
    "    - **`balance_classes`**:\n",
    "        - When True, the dataset is rebalanced to equalize the number of instances in each class during training. This can improve recall for the minority class but may affect precision.\n",
    "        - When False, the model trains on the original class distribution.\n",
    "\n",
    "\n",
    "2. **Search Strategy**:\n",
    "    - A **Cartesian grid search** is used, which exhaustively evaluates all combinations of hyperparameter values to ensure comprehensive coverage.\n",
    "\n",
    "3. **Evaluation Metrics**:\n",
    "    - **AUC**: Measures the model’s ability to distinguish between the positive and negative classes.\n",
    "    - **AUCPR**: Focuses on precision and recall, providing insight into performance on the minority class.\n",
    "\n",
    "4. **Procedure**:\n",
    "    - Perform the grid search on the training dataset.\n",
    "    - Sort and review models based on AUC and AUCPR to select the best-performing parameter set.\n",
    "    - Evaluate the best model on the test set to confirm generalizability.\n",
    "\n",
    "### Rationale:\n",
    "Grid search provides a structured approach to hyperparameter optimization, allowing us to test multiple configurations systematically. This is particularly useful for fine-tuning the balance between underfitting and overfitting, ensuring that the model achieves the best trade-off between bias and variance.\n",
    "\n",
    "By leveraging insights from the baseline model and the grid search results, we can refine our model to maximize predictive performance while maintaining interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "453ed464-9225-49de-9ac3-1d28cf33d5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Grid Build progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritwikgoel/.local/lib/python3.10/site-packages/h2o/grid/grid_search.py:434: UserWarning: Adding alpha array to hyperparameter runs slower with gridsearch. This is due to the fact that the algo has to run initialization for every alpha value. Setting the alpha array as a model parameter will skip the initialization and run faster overall.\n",
      "  warnings.warn(w_message)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-11.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-11 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-11 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-11 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table th,\n",
       "#h2o-table-11 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-11 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-11\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Hyper-Parameter Search Summary: ordered by increasing logloss</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>alpha</th>\n",
       "<th>missing_values_handling</th>\n",
       "<th>standardize</th>\n",
       "<th>model_ids</th>\n",
       "<th>logloss</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>0.0</td>\n",
       "<td>MeanImputation</td>\n",
       "<td>true</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_1</td>\n",
       "<td>0.4515904</td></tr>\n",
       "<tr><td></td>\n",
       "<td>1.0</td>\n",
       "<td>MeanImputation</td>\n",
       "<td>true</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_6</td>\n",
       "<td>0.4522731</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.75</td>\n",
       "<td>MeanImputation</td>\n",
       "<td>true</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_5</td>\n",
       "<td>0.4522948</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.5</td>\n",
       "<td>MeanImputation</td>\n",
       "<td>true</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_4</td>\n",
       "<td>0.4523557</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.25</td>\n",
       "<td>MeanImputation</td>\n",
       "<td>true</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_3</td>\n",
       "<td>0.4523679</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.01</td>\n",
       "<td>MeanImputation</td>\n",
       "<td>true</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_2</td>\n",
       "<td>0.4525528</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.0</td>\n",
       "<td>Skip</td>\n",
       "<td>true</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_7</td>\n",
       "<td>0.4679325</td></tr>\n",
       "<tr><td></td>\n",
       "<td>1.0</td>\n",
       "<td>Skip</td>\n",
       "<td>true</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_12</td>\n",
       "<td>0.4688519</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.75</td>\n",
       "<td>Skip</td>\n",
       "<td>true</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_11</td>\n",
       "<td>0.4688760</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.5</td>\n",
       "<td>Skip</td>\n",
       "<td>true</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_10</td>\n",
       "<td>0.4688831</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.25</td>\n",
       "<td>MeanImputation</td>\n",
       "<td>false</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_15</td>\n",
       "<td>0.4913922</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.5</td>\n",
       "<td>MeanImputation</td>\n",
       "<td>false</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_16</td>\n",
       "<td>0.4913922</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.75</td>\n",
       "<td>MeanImputation</td>\n",
       "<td>false</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_17</td>\n",
       "<td>0.4913922</td></tr>\n",
       "<tr><td></td>\n",
       "<td>1.0</td>\n",
       "<td>MeanImputation</td>\n",
       "<td>false</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_18</td>\n",
       "<td>0.4913922</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.01</td>\n",
       "<td>Skip</td>\n",
       "<td>false</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_20</td>\n",
       "<td>0.4918644</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.25</td>\n",
       "<td>Skip</td>\n",
       "<td>false</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_21</td>\n",
       "<td>0.4918644</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.5</td>\n",
       "<td>Skip</td>\n",
       "<td>false</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_22</td>\n",
       "<td>0.4918644</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.75</td>\n",
       "<td>Skip</td>\n",
       "<td>false</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_23</td>\n",
       "<td>0.4918644</td></tr>\n",
       "<tr><td></td>\n",
       "<td>1.0</td>\n",
       "<td>Skip</td>\n",
       "<td>false</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_24</td>\n",
       "<td>0.4918644</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.0</td>\n",
       "<td>Skip</td>\n",
       "<td>false</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_19</td>\n",
       "<td>0.5029036</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[24 rows x 6 columns]</pre>"
      ],
      "text/plain": [
       "Hyper-Parameter Search Summary: ordered by increasing logloss\n",
       "     alpha    missing_values_handling    standardize    model_ids                                                     logloss\n",
       "---  -------  -------------------------  -------------  ------------------------------------------------------------  -------------------\n",
       "     0.0      MeanImputation             true           Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_1   0.4515903997548848\n",
       "     1.0      MeanImputation             true           Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_6   0.45227305823384834\n",
       "     0.75     MeanImputation             true           Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_5   0.45229479752153984\n",
       "     0.5      MeanImputation             true           Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_4   0.45235572182715567\n",
       "     0.25     MeanImputation             true           Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_3   0.4523678941399821\n",
       "     0.01     MeanImputation             true           Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_2   0.45255278353620704\n",
       "     0.0      Skip                       true           Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_7   0.46793254819289554\n",
       "     1.0      Skip                       true           Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_12  0.4688519043055784\n",
       "     0.75     Skip                       true           Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_11  0.4688759566346781\n",
       "     0.5      Skip                       true           Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_10  0.46888310549396617\n",
       "---  ---      ---                        ---            ---                                                           ---\n",
       "     0.25     MeanImputation             false          Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_15  0.4913921783946723\n",
       "     0.5      MeanImputation             false          Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_16  0.4913921783946723\n",
       "     0.75     MeanImputation             false          Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_17  0.4913921783946723\n",
       "     1.0      MeanImputation             false          Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_18  0.4913921783946723\n",
       "     0.01     Skip                       false          Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_20  0.4918644008781431\n",
       "     0.25     Skip                       false          Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_21  0.4918644008781431\n",
       "     0.5      Skip                       false          Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_22  0.4918644008781431\n",
       "     0.75     Skip                       false          Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_23  0.4918644008781431\n",
       "     1.0      Skip                       false          Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_24  0.4918644008781431\n",
       "     0.0      Skip                       false          Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_19  0.5029035857928821\n",
       "[24 rows x 6 columns]\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define grid search hyperparameters\n",
    "glm_hyper_params = {\n",
    "    \"alpha\": [0.0, .01, 0.25, 0.5, 0.75, 1.0],  # Mix of L1 and L2\n",
    "    \"missing_values_handling\": [\"MeanImputation\", \"Skip\"],  # Handle missing values\n",
    "    \"standardize\": [True, False],  # Standardize predictors\n",
    "}\n",
    "\n",
    "# Define the search criteria\n",
    "search_criteria = {\n",
    "    \"strategy\": \"Cartesian\"  # Exhaustive search through all combinations\n",
    "}\n",
    "\n",
    "# Run grid search\n",
    "glm_grid = H2OGridSearch(\n",
    "    model=H2OGeneralizedLinearEstimator(\n",
    "        family=\"binomial\",\n",
    "        lambda_search=True,  # Auto-tune lambda\n",
    "        balance_classes=True\n",
    "    ),\n",
    "    hyper_params=glm_hyper_params,\n",
    "    search_criteria=search_criteria\n",
    ")\n",
    "\n",
    "# Train grid search models\n",
    "glm_grid.train(\n",
    "    y=\"loan_default\",\n",
    "    training_frame=train_hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28a245ff-8e34-4b7b-84d2-0f8356743ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-12.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-12 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-12 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-12 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-12 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-12 .h2o-table th,\n",
       "#h2o-table-12 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-12 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-12\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Hyper-Parameter Search Summary: ordered by decreasing aucpr</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>alpha</th>\n",
       "<th>missing_values_handling</th>\n",
       "<th>standardize</th>\n",
       "<th>model_ids</th>\n",
       "<th>aucpr</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>0.0</td>\n",
       "<td>Skip</td>\n",
       "<td>true</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_7</td>\n",
       "<td>0.3595545</td></tr>\n",
       "<tr><td></td>\n",
       "<td>1.0</td>\n",
       "<td>Skip</td>\n",
       "<td>true</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_12</td>\n",
       "<td>0.3563044</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.75</td>\n",
       "<td>Skip</td>\n",
       "<td>true</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_11</td>\n",
       "<td>0.3561428</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.5</td>\n",
       "<td>Skip</td>\n",
       "<td>true</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_10</td>\n",
       "<td>0.3560688</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.25</td>\n",
       "<td>Skip</td>\n",
       "<td>true</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_9</td>\n",
       "<td>0.3557789</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.01</td>\n",
       "<td>Skip</td>\n",
       "<td>true</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_8</td>\n",
       "<td>0.3550119</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.0</td>\n",
       "<td>MeanImputation</td>\n",
       "<td>true</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_1</td>\n",
       "<td>0.3471609</td></tr>\n",
       "<tr><td></td>\n",
       "<td>1.0</td>\n",
       "<td>MeanImputation</td>\n",
       "<td>true</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_6</td>\n",
       "<td>0.3446580</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.75</td>\n",
       "<td>MeanImputation</td>\n",
       "<td>true</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_5</td>\n",
       "<td>0.3445554</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.5</td>\n",
       "<td>MeanImputation</td>\n",
       "<td>true</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_4</td>\n",
       "<td>0.3443714</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.01</td>\n",
       "<td>Skip</td>\n",
       "<td>false</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_20</td>\n",
       "<td>0.2049857</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.25</td>\n",
       "<td>Skip</td>\n",
       "<td>false</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_21</td>\n",
       "<td>0.2049857</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.5</td>\n",
       "<td>Skip</td>\n",
       "<td>false</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_22</td>\n",
       "<td>0.2049857</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.75</td>\n",
       "<td>Skip</td>\n",
       "<td>false</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_23</td>\n",
       "<td>0.2049857</td></tr>\n",
       "<tr><td></td>\n",
       "<td>1.0</td>\n",
       "<td>Skip</td>\n",
       "<td>false</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_24</td>\n",
       "<td>0.2049857</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.01</td>\n",
       "<td>MeanImputation</td>\n",
       "<td>false</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_14</td>\n",
       "<td>0.2042045</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.25</td>\n",
       "<td>MeanImputation</td>\n",
       "<td>false</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_15</td>\n",
       "<td>0.2042045</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.5</td>\n",
       "<td>MeanImputation</td>\n",
       "<td>false</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_16</td>\n",
       "<td>0.2042045</td></tr>\n",
       "<tr><td></td>\n",
       "<td>0.75</td>\n",
       "<td>MeanImputation</td>\n",
       "<td>false</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_17</td>\n",
       "<td>0.2042045</td></tr>\n",
       "<tr><td></td>\n",
       "<td>1.0</td>\n",
       "<td>MeanImputation</td>\n",
       "<td>false</td>\n",
       "<td>Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_18</td>\n",
       "<td>0.2042045</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[24 rows x 6 columns]</pre>"
      ],
      "text/plain": [
       "Hyper-Parameter Search Summary: ordered by decreasing aucpr\n",
       "     alpha    missing_values_handling    standardize    model_ids                                                     aucpr\n",
       "---  -------  -------------------------  -------------  ------------------------------------------------------------  -------------------\n",
       "     0.0      Skip                       true           Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_7   0.35955447496934173\n",
       "     1.0      Skip                       true           Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_12  0.35630443401035783\n",
       "     0.75     Skip                       true           Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_11  0.356142770457068\n",
       "     0.5      Skip                       true           Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_10  0.3560687761820125\n",
       "     0.25     Skip                       true           Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_9   0.35577887859131074\n",
       "     0.01     Skip                       true           Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_8   0.35501191433664503\n",
       "     0.0      MeanImputation             true           Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_1   0.347160949125616\n",
       "     1.0      MeanImputation             true           Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_6   0.3446580178151709\n",
       "     0.75     MeanImputation             true           Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_5   0.3445554154011382\n",
       "     0.5      MeanImputation             true           Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_4   0.3443714251017592\n",
       "---  ---      ---                        ---            ---                                                           ---\n",
       "     0.01     Skip                       false          Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_20  0.20498574840425068\n",
       "     0.25     Skip                       false          Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_21  0.20498574840425068\n",
       "     0.5      Skip                       false          Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_22  0.20498574840425068\n",
       "     0.75     Skip                       false          Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_23  0.20498574840425068\n",
       "     1.0      Skip                       false          Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_24  0.20498574840425068\n",
       "     0.01     MeanImputation             false          Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_14  0.20420452468863612\n",
       "     0.25     MeanImputation             false          Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_15  0.20420452468863612\n",
       "     0.5      MeanImputation             false          Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_16  0.20420452468863612\n",
       "     0.75     MeanImputation             false          Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_17  0.20420452468863612\n",
       "     1.0      MeanImputation             false          Grid_GLM_py_1_sid_a941_model_python_1732816896406_4_model_18  0.20420452468863612\n",
       "[24 rows x 6 columns]\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the grid results, sorted by validation AUC\n",
    "glm_gridperf = glm_grid.get_grid(sort_by='aucpr', decreasing=True)\n",
    "glm_gridperf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e7798ad-a1bf-4dd6-8e63-b5a8eaa157ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomialGLM: glm\n",
       "** Reported on test data. **\n",
       "\n",
       "MSE: 0.14955664556458995\n",
       "RMSE: 0.3867255429430411\n",
       "LogLoss: 0.46652728627167417\n",
       "AUC: 0.698041219799806\n",
       "AUCPR: 0.3663532159308705\n",
       "Gini: 0.3960824395996121\n",
       "Null degrees of freedom: 11657\n",
       "Residual degrees of freedom: 11493\n",
       "Null deviance: 11827.545044006027\n",
       "Residual deviance: 10877.550206710359\n",
       "AIC: 11207.550206710359</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-13.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-13 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-13 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-13 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-13 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-13 .h2o-table th,\n",
       "#h2o-table-13 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-13 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-13\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.22294213747959407</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>6298.0</td>\n",
       "<td>2970.0</td>\n",
       "<td>0.3205</td>\n",
       "<td> (2970.0/9268.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>943.0</td>\n",
       "<td>1447.0</td>\n",
       "<td>0.3946</td>\n",
       "<td> (943.0/2390.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>7241.0</td>\n",
       "<td>4417.0</td>\n",
       "<td>0.3356</td>\n",
       "<td> (3913.0/11658.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-14.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-14 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-14 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-14 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-14 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-14 .h2o-table th,\n",
       "#h2o-table-14 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-14 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-14\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.2229421</td>\n",
       "<td>0.4251506</td>\n",
       "<td>208.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1195048</td>\n",
       "<td>0.5935242</td>\n",
       "<td>308.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3045721</td>\n",
       "<td>0.3968103</td>\n",
       "<td>140.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4963541</td>\n",
       "<td>0.7970492</td>\n",
       "<td>44.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.7010671</td>\n",
       "<td>0.7272727</td>\n",
       "<td>7.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0048186</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9997455</td>\n",
       "<td>0.9998921</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2463829</td>\n",
       "<td>0.2384123</td>\n",
       "<td>187.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2112182</td>\n",
       "<td>0.6370306</td>\n",
       "<td>219.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2229421</td>\n",
       "<td>0.6424909</td>\n",
       "<td>208.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9997455</td>\n",
       "<td>9267.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9997455</td>\n",
       "<td>2390.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0006883</td>\n",
       "<td>9268.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0048186</td>\n",
       "<td>2390.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9997455</td>\n",
       "<td>0.9998921</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9997455</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0006883</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0048186</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-15.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-15 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-15 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-15 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-15 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-15 .h2o-table th,\n",
       "#h2o-table-15 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-15 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-15\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 20.50 %, avg score: 20.36 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0100360</td>\n",
       "<td>0.5369209</td>\n",
       "<td>2.7515932</td>\n",
       "<td>2.7515932</td>\n",
       "<td>0.5641026</td>\n",
       "<td>0.6071702</td>\n",
       "<td>0.5641026</td>\n",
       "<td>0.6071702</td>\n",
       "<td>0.0276151</td>\n",
       "<td>0.0276151</td>\n",
       "<td>175.1593177</td>\n",
       "<td>175.1593177</td>\n",
       "<td>0.0221123</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0200721</td>\n",
       "<td>0.4809341</td>\n",
       "<td>2.5431391</td>\n",
       "<td>2.6473662</td>\n",
       "<td>0.5213675</td>\n",
       "<td>0.5067077</td>\n",
       "<td>0.5427350</td>\n",
       "<td>0.5569389</td>\n",
       "<td>0.0255230</td>\n",
       "<td>0.0531381</td>\n",
       "<td>154.3139148</td>\n",
       "<td>164.7366162</td>\n",
       "<td>0.0415930</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0300223</td>\n",
       "<td>0.4550617</td>\n",
       "<td>2.5230126</td>\n",
       "<td>2.6061518</td>\n",
       "<td>0.5172414</td>\n",
       "<td>0.4670907</td>\n",
       "<td>0.5342857</td>\n",
       "<td>0.5271607</td>\n",
       "<td>0.0251046</td>\n",
       "<td>0.0782427</td>\n",
       "<td>152.3012552</td>\n",
       "<td>160.6151823</td>\n",
       "<td>0.0606553</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0400583</td>\n",
       "<td>0.4317479</td>\n",
       "<td>1.9177771</td>\n",
       "<td>2.4336896</td>\n",
       "<td>0.3931624</td>\n",
       "<td>0.4424585</td>\n",
       "<td>0.4989293</td>\n",
       "<td>0.5059398</td>\n",
       "<td>0.0192469</td>\n",
       "<td>0.0974895</td>\n",
       "<td>91.7777063</td>\n",
       "<td>143.3689624</td>\n",
       "<td>0.0722414</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0500086</td>\n",
       "<td>0.4123716</td>\n",
       "<td>2.3127615</td>\n",
       "<td>2.4096285</td>\n",
       "<td>0.4741379</td>\n",
       "<td>0.4218479</td>\n",
       "<td>0.4939966</td>\n",
       "<td>0.4892079</td>\n",
       "<td>0.0230126</td>\n",
       "<td>0.1205021</td>\n",
       "<td>131.2761506</td>\n",
       "<td>140.9628455</td>\n",
       "<td>0.0886721</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1000172</td>\n",
       "<td>0.3553717</td>\n",
       "<td>1.8908890</td>\n",
       "<td>2.1502587</td>\n",
       "<td>0.3876501</td>\n",
       "<td>0.3816036</td>\n",
       "<td>0.4408233</td>\n",
       "<td>0.4354058</td>\n",
       "<td>0.0945607</td>\n",
       "<td>0.2150628</td>\n",
       "<td>89.0888996</td>\n",
       "<td>115.0258725</td>\n",
       "<td>0.1447132</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1500257</td>\n",
       "<td>0.3173323</td>\n",
       "<td>1.8323216</td>\n",
       "<td>2.0442797</td>\n",
       "<td>0.3756432</td>\n",
       "<td>0.3351588</td>\n",
       "<td>0.4190966</td>\n",
       "<td>0.4019901</td>\n",
       "<td>0.0916318</td>\n",
       "<td>0.3066946</td>\n",
       "<td>83.2321637</td>\n",
       "<td>104.4279696</td>\n",
       "<td>0.1970700</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2000343</td>\n",
       "<td>0.2891589</td>\n",
       "<td>1.5227513</td>\n",
       "<td>1.9138976</td>\n",
       "<td>0.3121784</td>\n",
       "<td>0.3030571</td>\n",
       "<td>0.3923671</td>\n",
       "<td>0.3772569</td>\n",
       "<td>0.0761506</td>\n",
       "<td>0.3828452</td>\n",
       "<td>52.2751315</td>\n",
       "<td>91.3897601</td>\n",
       "<td>0.2299535</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3000515</td>\n",
       "<td>0.2487686</td>\n",
       "<td>1.3261323</td>\n",
       "<td>1.7179758</td>\n",
       "<td>0.2718696</td>\n",
       "<td>0.2678954</td>\n",
       "<td>0.3522013</td>\n",
       "<td>0.3408031</td>\n",
       "<td>0.1326360</td>\n",
       "<td>0.5154812</td>\n",
       "<td>32.6132327</td>\n",
       "<td>71.7975843</td>\n",
       "<td>0.2709840</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3999828</td>\n",
       "<td>0.2162079</td>\n",
       "<td>1.0425564</td>\n",
       "<td>1.5492296</td>\n",
       "<td>0.2137339</td>\n",
       "<td>0.2313230</td>\n",
       "<td>0.3176067</td>\n",
       "<td>0.3134506</td>\n",
       "<td>0.1041841</td>\n",
       "<td>0.6196653</td>\n",
       "<td>4.2556431</td>\n",
       "<td>54.9229625</td>\n",
       "<td>0.2763334</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.1874158</td>\n",
       "<td>0.9914617</td>\n",
       "<td>1.4376569</td>\n",
       "<td>0.2032590</td>\n",
       "<td>0.2017705</td>\n",
       "<td>0.2947332</td>\n",
       "<td>0.2911108</td>\n",
       "<td>0.0991632</td>\n",
       "<td>0.7188285</td>\n",
       "<td>-0.8538292</td>\n",
       "<td>43.7656904</td>\n",
       "<td>0.2752592</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6000172</td>\n",
       "<td>0.1606609</td>\n",
       "<td>0.8952439</td>\n",
       "<td>1.3472418</td>\n",
       "<td>0.1835334</td>\n",
       "<td>0.1739294</td>\n",
       "<td>0.2761973</td>\n",
       "<td>0.2715778</td>\n",
       "<td>0.0895397</td>\n",
       "<td>0.8083682</td>\n",
       "<td>-10.4756095</td>\n",
       "<td>34.7241813</td>\n",
       "<td>0.2620799</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6999485</td>\n",
       "<td>0.1347185</td>\n",
       "<td>0.6741028</td>\n",
       "<td>1.2511380</td>\n",
       "<td>0.1381974</td>\n",
       "<td>0.1476892</td>\n",
       "<td>0.2564951</td>\n",
       "<td>0.2538902</td>\n",
       "<td>0.0673640</td>\n",
       "<td>0.8757322</td>\n",
       "<td>-32.5897247</td>\n",
       "<td>25.1138014</td>\n",
       "<td>0.2211142</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7999657</td>\n",
       "<td>0.1068360</td>\n",
       "<td>0.6107739</td>\n",
       "<td>1.1710753</td>\n",
       "<td>0.1252144</td>\n",
       "<td>0.1213362</td>\n",
       "<td>0.2400815</td>\n",
       "<td>0.2373174</td>\n",
       "<td>0.0610879</td>\n",
       "<td>0.9368201</td>\n",
       "<td>-38.9226121</td>\n",
       "<td>17.1075331</td>\n",
       "<td>0.1721459</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8999828</td>\n",
       "<td>0.0728011</td>\n",
       "<td>0.4141549</td>\n",
       "<td>1.0869570</td>\n",
       "<td>0.0849057</td>\n",
       "<td>0.0907296</td>\n",
       "<td>0.2228364</td>\n",
       "<td>0.2210268</td>\n",
       "<td>0.0414226</td>\n",
       "<td>0.9782427</td>\n",
       "<td>-58.5845109</td>\n",
       "<td>8.6957028</td>\n",
       "<td>0.0984412</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000838</td>\n",
       "<td>0.2175359</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0445969</td>\n",
       "<td>0.0471810</td>\n",
       "<td>0.2050094</td>\n",
       "<td>0.2036392</td>\n",
       "<td>0.0217573</td>\n",
       "<td>1.0</td>\n",
       "<td>-78.2464098</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>"
      ],
      "text/plain": [
       "ModelMetricsBinomialGLM: glm\n",
       "** Reported on test data. **\n",
       "\n",
       "MSE: 0.14955664556458995\n",
       "RMSE: 0.3867255429430411\n",
       "LogLoss: 0.46652728627167417\n",
       "AUC: 0.698041219799806\n",
       "AUCPR: 0.3663532159308705\n",
       "Gini: 0.3960824395996121\n",
       "Null degrees of freedom: 11657\n",
       "Residual degrees of freedom: 11493\n",
       "Null deviance: 11827.545044006027\n",
       "Residual deviance: 10877.550206710359\n",
       "AIC: 11207.550206710359\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.22294213747959407\n",
       "       0     1     Error    Rate\n",
       "-----  ----  ----  -------  ----------------\n",
       "0      6298  2970  0.3205   (2970.0/9268.0)\n",
       "1      943   1447  0.3946   (943.0/2390.0)\n",
       "Total  7241  4417  0.3356   (3913.0/11658.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.222942     0.425151  208\n",
       "max f2                       0.119505     0.593524  308\n",
       "max f0point5                 0.304572     0.39681   140\n",
       "max accuracy                 0.496354     0.797049  44\n",
       "max precision                0.701067     0.727273  7\n",
       "max recall                   0.00481864   1         398\n",
       "max specificity              0.999746     0.999892  0\n",
       "max absolute_mcc             0.246383     0.238412  187\n",
       "max min_per_class_accuracy   0.211218     0.637031  219\n",
       "max mean_per_class_accuracy  0.222942     0.642491  208\n",
       "max tns                      0.999746     9267      0\n",
       "max fns                      0.999746     2390      0\n",
       "max fps                      0.000688277  9268      399\n",
       "max tps                      0.00481864   2390      398\n",
       "max tnr                      0.999746     0.999892  0\n",
       "max fnr                      0.999746     1         0\n",
       "max fpr                      0.000688277  1         399\n",
       "max tpr                      0.00481864   1         398\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 20.50 %, avg score: 20.36 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain       cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  ---------  -----------------  --------------------\n",
       "1        0.010036                    0.536921           2.75159   2.75159            0.564103         0.60717    0.564103                    0.60717             0.0276151       0.0276151                  175.159    175.159            0.0221123\n",
       "2        0.0200721                   0.480934           2.54314   2.64737            0.521368         0.506708   0.542735                    0.556939            0.025523        0.0531381                  154.314    164.737            0.041593\n",
       "3        0.0300223                   0.455062           2.52301   2.60615            0.517241         0.467091   0.534286                    0.527161            0.0251046       0.0782427                  152.301    160.615            0.0606553\n",
       "4        0.0400583                   0.431748           1.91778   2.43369            0.393162         0.442458   0.498929                    0.50594             0.0192469       0.0974895                  91.7777    143.369            0.0722414\n",
       "5        0.0500086                   0.412372           2.31276   2.40963            0.474138         0.421848   0.493997                    0.489208            0.0230126       0.120502                   131.276    140.963            0.0886721\n",
       "6        0.100017                    0.355372           1.89089   2.15026            0.38765          0.381604   0.440823                    0.435406            0.0945607       0.215063                   89.0889    115.026            0.144713\n",
       "7        0.150026                    0.317332           1.83232   2.04428            0.375643         0.335159   0.419097                    0.40199             0.0916318       0.306695                   83.2322    104.428            0.19707\n",
       "8        0.200034                    0.289159           1.52275   1.9139             0.312178         0.303057   0.392367                    0.377257            0.0761506       0.382845                   52.2751    91.3898            0.229954\n",
       "9        0.300051                    0.248769           1.32613   1.71798            0.27187          0.267895   0.352201                    0.340803            0.132636        0.515481                   32.6132    71.7976            0.270984\n",
       "10       0.399983                    0.216208           1.04256   1.54923            0.213734         0.231323   0.317607                    0.313451            0.104184        0.619665                   4.25564    54.923             0.276333\n",
       "11       0.5                         0.187416           0.991462  1.43766            0.203259         0.201771   0.294733                    0.291111            0.0991632       0.718828                   -0.853829  43.7657            0.275259\n",
       "12       0.600017                    0.160661           0.895244  1.34724            0.183533         0.173929   0.276197                    0.271578            0.0895397       0.808368                   -10.4756   34.7242            0.26208\n",
       "13       0.699949                    0.134718           0.674103  1.25114            0.138197         0.147689   0.256495                    0.25389             0.067364        0.875732                   -32.5897   25.1138            0.221114\n",
       "14       0.799966                    0.106836           0.610774  1.17108            0.125214         0.121336   0.240081                    0.237317            0.0610879       0.93682                    -38.9226   17.1075            0.172146\n",
       "15       0.899983                    0.0728011          0.414155  1.08696            0.0849057        0.0907296  0.222836                    0.221027            0.0414226       0.978243                   -58.5845   8.6957             0.0984412\n",
       "16       1                           8.3842e-05         0.217536  1                  0.0445969        0.047181   0.205009                    0.203639            0.0217573       1                          -78.2464   0                  0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the models based on best AUCPR value\n",
    "glm_gridperf = glm_grid.get_grid(sort_by='aucpr', decreasing=True)\n",
    "\n",
    "# Grab the top GLM model, chosen by validation AUCPR\n",
    "best_glm = glm_gridperf.models[0]\n",
    "\n",
    "best_glm.model_performance(test_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3eff8803-c067-441b-8108-adea84bcc51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritwikgoel/.local/lib/python3.10/site-packages/h2o/job.py:81: UserWarning: Test/Validation dataset column 'MB007' has levels not trained on: [\"AND\", \"APPLE\", \"BOWAY\", \"DOOVL5PRO\", \"MANN\", \"MC-X7MINI\", \"RAMOS\", \"TINAI\", \"VOLTE\"]\n",
      "  warnings.warn(w)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">        p0</th><th style=\"text-align: right;\">         p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>0        </td><td style=\"text-align: right;\">  0.853919</td><td style=\"text-align: right;\">  0.146081 </td></tr>\n",
       "<tr><td>0        </td><td style=\"text-align: right;\">  0.909841</td><td style=\"text-align: right;\">  0.0901588</td></tr>\n",
       "<tr><td>0        </td><td style=\"text-align: right;\">  0.913544</td><td style=\"text-align: right;\">  0.0864557</td></tr>\n",
       "<tr><td>         </td><td style=\"text-align: right;\">nan       </td><td style=\"text-align: right;\">nan        </td></tr>\n",
       "<tr><td>1        </td><td style=\"text-align: right;\">  0.750373</td><td style=\"text-align: right;\">  0.249627 </td></tr>\n",
       "<tr><td>1        </td><td style=\"text-align: right;\">  0.774182</td><td style=\"text-align: right;\">  0.225818 </td></tr>\n",
       "<tr><td>0        </td><td style=\"text-align: right;\">  0.967319</td><td style=\"text-align: right;\">  0.0326815</td></tr>\n",
       "<tr><td>         </td><td style=\"text-align: right;\">nan       </td><td style=\"text-align: right;\">nan        </td></tr>\n",
       "<tr><td>1        </td><td style=\"text-align: right;\">  0.723551</td><td style=\"text-align: right;\">  0.276449 </td></tr>\n",
       "<tr><td>         </td><td style=\"text-align: right;\">nan       </td><td style=\"text-align: right;\">nan        </td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[16000 rows x 3 columns]</pre>"
      ],
      "text/plain": [
       "predict            p0           p1\n",
       "---------  ----------  -----------\n",
       "0            0.853919    0.146081\n",
       "0            0.909841    0.0901588\n",
       "0            0.913544    0.0864557\n",
       "           nan         nan\n",
       "1            0.750373    0.249627\n",
       "1            0.774182    0.225818\n",
       "0            0.967319    0.0326815\n",
       "           nan         nan\n",
       "1            0.723551    0.276449\n",
       "           nan         nan\n",
       "[16000 rows x 3 columns]\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_glm.predict(test_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca70911f-862e-4247-8c06-fbc833dd51b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGains(model):\n",
    "    predictions = model.predict(test_hf)\n",
    "    test_scores = test_hf['loan_default'].cbind(predictions).as_data_frame()\n",
    "    #sort on prediction (descending), add id, and decile for groups containing 1/10 of datapoints\n",
    "    test_scores = test_scores.sort_values(by='predict',ascending=False)\n",
    "    test_scores['row_id'] = range(0,0+len(test_scores))\n",
    "    test_scores['decile'] = ( test_scores['row_id'] / (len(test_scores)/10) ).astype(int)\n",
    "    #see count by decile\n",
    "    test_scores.loc[test_scores['decile'] == 10]=9\n",
    "    test_scores['decile'].value_counts()\n",
    "\n",
    "    #create gains table\n",
    "    gains = test_scores.groupby('decile')['loan_default'].agg(['count','sum'])\n",
    "    gains.columns = ['count','actual']\n",
    "    gains\n",
    "\n",
    "    #add features to gains table\n",
    "    gains['non_actual'] = gains['count'] - gains['actual']\n",
    "    gains['cum_count'] = gains['count'].cumsum()\n",
    "    gains['cum_actual'] = gains['actual'].cumsum()\n",
    "    gains['cum_non_actual'] = gains['non_actual'].cumsum()\n",
    "    gains['percent_cum_actual'] = (gains['cum_actual'] / np.max(gains['cum_actual'])).round(2)\n",
    "    gains['percent_cum_non_actual'] = (gains['cum_non_actual'] / np.max(gains['cum_non_actual'])).round(2)\n",
    "    gains['if_random'] = np.max(gains['cum_actual']) /10 \n",
    "    gains['if_random'] = gains['if_random'].cumsum()\n",
    "    gains['lift'] = (gains['cum_actual'] / gains['if_random']).round(2)\n",
    "    gains['K_S'] = np.abs( gains['percent_cum_actual'] -  gains['percent_cum_non_actual'] ) * 100\n",
    "    gains['gain']=(gains['cum_actual']/gains['cum_count']*100).round(2)\n",
    "    gains = pd.DataFrame(gains)\n",
    "    return(gains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe071ad6-331f-41a3-bd9d-fdd28199e760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritwikgoel/.local/lib/python3.10/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>actual</th>\n",
       "      <th>non_actual</th>\n",
       "      <th>cum_count</th>\n",
       "      <th>cum_actual</th>\n",
       "      <th>cum_non_actual</th>\n",
       "      <th>percent_cum_actual</th>\n",
       "      <th>percent_cum_non_actual</th>\n",
       "      <th>if_random</th>\n",
       "      <th>lift</th>\n",
       "      <th>K_S</th>\n",
       "      <th>gain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1600</td>\n",
       "      <td>491</td>\n",
       "      <td>1109</td>\n",
       "      <td>1600</td>\n",
       "      <td>491</td>\n",
       "      <td>1109</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>309.8</td>\n",
       "      <td>1.58</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1600</td>\n",
       "      <td>476</td>\n",
       "      <td>1124</td>\n",
       "      <td>3200</td>\n",
       "      <td>967</td>\n",
       "      <td>2233</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.17</td>\n",
       "      <td>619.6</td>\n",
       "      <td>1.56</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1600</td>\n",
       "      <td>487</td>\n",
       "      <td>1113</td>\n",
       "      <td>4800</td>\n",
       "      <td>1454</td>\n",
       "      <td>3346</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.26</td>\n",
       "      <td>929.4</td>\n",
       "      <td>1.56</td>\n",
       "      <td>21.0</td>\n",
       "      <td>30.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600</td>\n",
       "      <td>280</td>\n",
       "      <td>1320</td>\n",
       "      <td>6400</td>\n",
       "      <td>1734</td>\n",
       "      <td>4666</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1239.2</td>\n",
       "      <td>1.40</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1600</td>\n",
       "      <td>214</td>\n",
       "      <td>1386</td>\n",
       "      <td>8000</td>\n",
       "      <td>1948</td>\n",
       "      <td>6052</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>1.26</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1600</td>\n",
       "      <td>195</td>\n",
       "      <td>1405</td>\n",
       "      <td>9600</td>\n",
       "      <td>2143</td>\n",
       "      <td>7457</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1858.8</td>\n",
       "      <td>1.15</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1600</td>\n",
       "      <td>192</td>\n",
       "      <td>1408</td>\n",
       "      <td>11200</td>\n",
       "      <td>2335</td>\n",
       "      <td>8865</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.69</td>\n",
       "      <td>2168.6</td>\n",
       "      <td>1.08</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1600</td>\n",
       "      <td>249</td>\n",
       "      <td>1351</td>\n",
       "      <td>12800</td>\n",
       "      <td>2584</td>\n",
       "      <td>10216</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2478.4</td>\n",
       "      <td>1.04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1600</td>\n",
       "      <td>271</td>\n",
       "      <td>1329</td>\n",
       "      <td>14400</td>\n",
       "      <td>2855</td>\n",
       "      <td>11545</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2788.2</td>\n",
       "      <td>1.02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1600</td>\n",
       "      <td>243</td>\n",
       "      <td>1357</td>\n",
       "      <td>16000</td>\n",
       "      <td>3098</td>\n",
       "      <td>12902</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3098.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count  actual  non_actual  cum_count  cum_actual  cum_non_actual  \\\n",
       "decile                                                                     \n",
       "0        1600     491        1109       1600         491            1109   \n",
       "1        1600     476        1124       3200         967            2233   \n",
       "2        1600     487        1113       4800        1454            3346   \n",
       "3        1600     280        1320       6400        1734            4666   \n",
       "4        1600     214        1386       8000        1948            6052   \n",
       "5        1600     195        1405       9600        2143            7457   \n",
       "6        1600     192        1408      11200        2335            8865   \n",
       "7        1600     249        1351      12800        2584           10216   \n",
       "8        1600     271        1329      14400        2855           11545   \n",
       "9        1600     243        1357      16000        3098           12902   \n",
       "\n",
       "        percent_cum_actual  percent_cum_non_actual  if_random  lift   K_S  \\\n",
       "decile                                                                      \n",
       "0                     0.16                    0.09      309.8  1.58   7.0   \n",
       "1                     0.31                    0.17      619.6  1.56  14.0   \n",
       "2                     0.47                    0.26      929.4  1.56  21.0   \n",
       "3                     0.56                    0.36     1239.2  1.40  20.0   \n",
       "4                     0.63                    0.47     1549.0  1.26  16.0   \n",
       "5                     0.69                    0.58     1858.8  1.15  11.0   \n",
       "6                     0.75                    0.69     2168.6  1.08   6.0   \n",
       "7                     0.83                    0.79     2478.4  1.04   4.0   \n",
       "8                     0.92                    0.89     2788.2  1.02   3.0   \n",
       "9                     1.00                    1.00     3098.0  1.00   0.0   \n",
       "\n",
       "         gain  \n",
       "decile         \n",
       "0       30.69  \n",
       "1       30.22  \n",
       "2       30.29  \n",
       "3       27.09  \n",
       "4       24.35  \n",
       "5       22.32  \n",
       "6       20.85  \n",
       "7       20.19  \n",
       "8       19.83  \n",
       "9       19.36  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createGains(best_glm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2c981a9-b7ef-4d30-ae6d-987bb027715d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritwikgoel/.local/lib/python3.10/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    }
   ],
   "source": [
    "y_actual = test_hf['loan_default'].as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "222e4950-5675-4ba5-8c5a-6394ea609a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC_AUC(my_result, df, target):\n",
    "    from sklearn.metrics import roc_curve, auc, average_precision_score, precision_recall_curve\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    # Extract actual and predicted values\n",
    "    y_actual = df[target].as_data_frame().values.flatten()\n",
    "    y_pred = my_result.predict(df)[\"p1\"].as_data_frame().values.flatten()\n",
    "\n",
    "    # Remove rows with NaN predictions\n",
    "    valid_indices = ~np.isnan(y_pred)\n",
    "    y_actual = y_actual[valid_indices]\n",
    "    y_pred = y_pred[valid_indices]\n",
    "\n",
    "    # Check for valid inputs\n",
    "    if len(y_actual) != len(y_pred):\n",
    "        raise ValueError(\"Length of actual and predicted values must match.\")\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_actual, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(y_actual, y_pred)\n",
    "    average_precision = average_precision_score(y_actual, y_pred)\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\n   * ROC curve: Plots the true positive rate (TPR) vs. false positive rate (FPR)\")\n",
    "    print(\"   * AUC: Area under the ROC curve (0.5: random, 1.0: perfect accuracy)\")\n",
    "    print(\"   * Recall (R): True Positives / (True Positives + False Negatives)\\n\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Average Precision (Precision-Recall AUC): {average_precision:.4f}\")\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # ROC Curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=\"ROC curve (AUC = %0.2f)\" % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")  # Diagonal line\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve: AUC = {:.4f}\".format(roc_auc))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    # Precision-Recall Curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.step(recall, precision, color=\"b\", alpha=0.8, where=\"post\", label=\"PR curve\")\n",
    "    plt.fill_between(recall, precision, step=\"post\", alpha=0.2, color=\"b\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title(\"Precision-Recall Curve: PR AUC = {:.4f}\".format(average_precision))\n",
    "    plt.legend(loc=\"lower left\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed3a61e5-befe-432a-a135-a6a9ab1973f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritwikgoel/.local/lib/python3.10/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "███████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      "   * ROC curve: Plots the true positive rate (TPR) vs. false positive rate (FPR)\n",
      "   * AUC: Area under the ROC curve (0.5: random, 1.0: perfect accuracy)\n",
      "   * Recall (R): True Positives / (True Positives + False Negatives)\n",
      "\n",
      "ROC AUC: 0.6981\n",
      "Average Precision (Precision-Recall AUC): 0.3668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritwikgoel/.local/lib/python3.10/site-packages/h2o/job.py:81: UserWarning: Test/Validation dataset column 'MB007' has levels not trained on: [\"AND\", \"APPLE\", \"BOWAY\", \"DOOVL5PRO\", \"MANN\", \"MC-X7MINI\", \"RAMOS\", \"TINAI\", \"VOLTE\"]\n",
      "  warnings.warn(w)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ROC_AUC(best_glm,test_hf,'loan_default')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed971282-4476-4d61-b6ec-f6ee0ba7a2ef",
   "metadata": {},
   "source": [
    "### **Results and Takeaways: Generalized Linear Model (GLM) Performance**\n",
    "\n",
    "#### **Model Results:**\n",
    "- **Best Model Configuration:**\n",
    "  - **Alpha**: `0.0` (No L1 regularization, fully relies on L2 penalty)\n",
    "  - **Missing Values Handling**: `Skip`\n",
    "  - **Standardize Predictors**: `True`\n",
    "  - **AUC**: `0.6981`\n",
    "  - **PR AUC**: `0.3668`\n",
    "\n",
    "#### **ROC Curve Observations:**\n",
    "- The **ROC AUC** value of `0.6981` indicates a fair ability of the model to distinguish between classes (better than random guessing but not highly accurate).\n",
    "- The curve shows gradual improvement across all thresholds but lacks sharp increases, reflecting moderate sensitivity and specificity.\n",
    "\n",
    "#### **Precision-Recall (PR) Curve Observations:**\n",
    "- The **PR AUC** value of `0.3668` reflects the model's ability to handle class imbalance. While reasonable, it suggests room for improvement in predicting positive cases (loan defaults).\n",
    "- Precision drops significantly as recall increases, indicating the challenge of maintaining high precision while improving recall.\n",
    "\n",
    "#### **Takeaways:**\n",
    "1. **Model Insights**:\n",
    "   - The best-performing model effectively skipped rows with missing values (`Skip` strategy) instead of imputing, which contributed to slightly better predictions.\n",
    "   - Using no L1 regularization (alpha = 0.0) allowed for a more flexible fit without enforcing sparsity in coefficients.\n",
    "\n",
    "2. **Performance Gaps**:\n",
    "   - While the ROC AUC is close to 0.70, indicating a moderate discriminatory ability, the PR AUC (~0.3668) shows that handling minority class predictions (loan defaults) remains challenging.\n",
    "\n",
    "3. **Next Steps**:\n",
    "   - Consider refining feature engineering, especially for categorical variables and interaction terms, to capture additional predictive signals.\n",
    "   - Explore alternative modeling approaches, such as ensemble methods (e.g., Random Forest, XGBoost), which may handle class imbalance and non-linear relationships more effectively.\n",
    "\n",
    "The results from the GLM provide a solid baseline but highlight areas for further improvement in both feature representation and model complexity. This concludes the GLM analysis section, with the next steps focusing on more sophisticated modeling techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0352520f-60e9-40c3-8ad0-7a12b7db9644",
   "metadata": {},
   "source": [
    "## H2O AutoML for Mortgage Default Prediction\n",
    "\n",
    "In this section, we leverage **H2O AutoML** to streamline the model-building process for predicting mortgage defaults. AutoML automates training and evaluation across multiple algorithms (e.g., GLM, GBM, Random Forest, Deep Learning) and ranks models based on performance metrics like AUC.\n",
    "\n",
    "### Why AutoML?\n",
    "- Eliminates the need for manual hyperparameter tuning.\n",
    "- Trains and compares diverse models efficiently.\n",
    "- Provides a leaderboard to identify the best-performing model for our dataset.\n",
    "\n",
    "We will use the preprocessed training and testing datasets, ensuring consistent evaluation metrics and results. Let's implement AutoML to determine the optimal model for this task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df9ad28a-7bd8-4fe3-aa88-e0db1988b53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\n",
      "model_id                                                    aucpr       auc    logloss    mean_per_class_error      rmse       mse\n",
      "StackedEnsemble_BestOfFamily_1_AutoML_1_20241128_130210  0.365915  0.711158   0.445967                0.351196  0.376762  0.14195\n",
      "StackedEnsemble_AllModels_1_AutoML_1_20241128_130210     0.364312  0.71115    0.44607                 0.35021   0.376881  0.14204\n",
      "XGBoost_grid_1_AutoML_1_20241128_130210_model_74         0.359817  0.708525   0.614491                0.353454  0.462849  0.214229\n",
      "DeepLearning_grid_3_AutoML_1_20241128_130210_model_6     0.359597  0.703178   0.466456                0.359356  0.384688  0.147985\n",
      "DeepLearning_grid_3_AutoML_1_20241128_130210_model_5     0.35933   0.704273   0.452758                0.35394   0.379279  0.143853\n",
      "DeepLearning_grid_3_AutoML_1_20241128_130210_model_9     0.359089  0.707615   0.451569                0.348665  0.379537  0.144048\n",
      "DeepLearning_grid_2_AutoML_1_20241128_130210_model_16    0.359012  0.701492   0.452196                0.351834  0.379029  0.143663\n",
      "XGBoost_grid_1_AutoML_1_20241128_130210_model_85         0.357838  0.705754   0.613795                0.352928  0.462646  0.214041\n",
      "GBM_grid_1_AutoML_1_20241128_130210_model_65             0.357778  0.704296   0.449452                0.353527  0.378407  0.143192\n",
      "XGBoost_grid_1_AutoML_1_20241128_130210_model_1          0.35688   0.704767   0.448566                0.357893  0.378085  0.142948\n",
      "[302 rows x 7 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import AutoML from H2O\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# Initialize AutoML with a runtime limit and desired settings\n",
    "automl = H2OAutoML(\n",
    "    max_runtime_secs=9*3600,  # 9 hour training limit\n",
    "    seed=42,  # For reproducibility\n",
    "    balance_classes=True,  # Handle class imbalance\n",
    "    stopping_metric=\"AUCPR\",  # Optimize based on AUCPR\n",
    "    sort_metric=\"AUCPR\",  # Sort leaderboard by AUCPR\n",
    "    max_models=300,  # Limit to 300 models for evaluation\n",
    "    nfolds=5  # Cross-validation for robust performance\n",
    ")\n",
    "\n",
    "# Train AutoML\n",
    "automl.train(\n",
    "    y=\"loan_default\",  # Target variable\n",
    "    training_frame=train_hf,\n",
    "    leaderboard_frame=test_hf  # Evaluate on test data for leaderboard rankings\n",
    ")\n",
    "\n",
    "# Display the leaderboard\n",
    "automl_leaderboard = automl.leaderboard\n",
    "print(automl_leaderboard)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbc9faf7-0623-4d61-a97e-ad4ff01f2bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritwikgoel/.local/lib/python3.10/site-packages/h2o/job.py:81: UserWarning: Test/Validation dataset column 'MB007' has levels not trained on: [\"AND\", \"APPLE\", \"BOWAY\", \"DOOVL5PRO\", \"MANN\", \"MC-X7MINI\", \"RAMOS\", \"TINAI\", \"VOLTE\"]\n",
      "  warnings.warn(w)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">      p0</th><th style=\"text-align: right;\">       p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.778726</td><td style=\"text-align: right;\">0.221274 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.917351</td><td style=\"text-align: right;\">0.0826493</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.909479</td><td style=\"text-align: right;\">0.0905208</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.758802</td><td style=\"text-align: right;\">0.241198 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.69856 </td><td style=\"text-align: right;\">0.30144  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.764238</td><td style=\"text-align: right;\">0.235762 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.959772</td><td style=\"text-align: right;\">0.0402283</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.985171</td><td style=\"text-align: right;\">0.0148294</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.753894</td><td style=\"text-align: right;\">0.246106 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.872068</td><td style=\"text-align: right;\">0.127932 </td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[10 rows x 3 columns]</pre>"
      ],
      "text/plain": [
       "  predict        p0         p1\n",
       "---------  --------  ---------\n",
       "        1  0.778726  0.221274\n",
       "        0  0.917351  0.0826493\n",
       "        0  0.909479  0.0905208\n",
       "        1  0.758802  0.241198\n",
       "        1  0.69856   0.30144\n",
       "        1  0.764238  0.235762\n",
       "        0  0.959772  0.0402283\n",
       "        0  0.985171  0.0148294\n",
       "        1  0.753894  0.246106\n",
       "        0  0.872068  0.127932\n",
       "[10 rows x 3 columns]\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = automl.predict(test_hf)\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0da7354e-f929-482d-8553-afcac631b81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomialGLM: stackedensemble\n",
       "** Reported on test data. **\n",
       "\n",
       "MSE: 0.14194955073836305\n",
       "RMSE: 0.37676192846194406\n",
       "LogLoss: 0.4459669197244253\n",
       "AUC: 0.7111584908991144\n",
       "AUCPR: 0.3659152389928349\n",
       "Gini: 0.42231698179822885\n",
       "Null degrees of freedom: 15999\n",
       "Residual degrees of freedom: 15994\n",
       "Null deviance: 15725.976585763\n",
       "Residual deviance: 14270.94143118161\n",
       "AIC: 14282.94143118161</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-16.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-16 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-16 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-16 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-16 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-16 .h2o-table th,\n",
       "#h2o-table-16 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-16 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-16\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.19930079046274846</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>8375.0</td>\n",
       "<td>4527.0</td>\n",
       "<td>0.3509</td>\n",
       "<td> (4527.0/12902.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>1089.0</td>\n",
       "<td>2009.0</td>\n",
       "<td>0.3515</td>\n",
       "<td> (1089.0/3098.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>9464.0</td>\n",
       "<td>6536.0</td>\n",
       "<td>0.351</td>\n",
       "<td> (5616.0/16000.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-17.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-17 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-17 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-17 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-17 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-17 .h2o-table th,\n",
       "#h2o-table-17 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-17 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-17\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.1993008</td>\n",
       "<td>0.4170646</td>\n",
       "<td>219.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1178950</td>\n",
       "<td>0.5884327</td>\n",
       "<td>303.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3179721</td>\n",
       "<td>0.3926483</td>\n",
       "<td>123.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4686127</td>\n",
       "<td>0.80875</td>\n",
       "<td>44.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.7472745</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0164975</td>\n",
       "<td>1.0</td>\n",
       "<td>394.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.7472745</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2569984</td>\n",
       "<td>0.2457651</td>\n",
       "<td>171.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1993008</td>\n",
       "<td>0.6484829</td>\n",
       "<td>219.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1993008</td>\n",
       "<td>0.6488035</td>\n",
       "<td>219.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.7472745</td>\n",
       "<td>12902.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.7472745</td>\n",
       "<td>3097.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0056747</td>\n",
       "<td>12902.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0164975</td>\n",
       "<td>3098.0</td>\n",
       "<td>394.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.7472745</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.7472745</td>\n",
       "<td>0.9996772</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0056747</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0164975</td>\n",
       "<td>1.0</td>\n",
       "<td>394.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-18.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-18 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-18 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-18 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-18 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-18 .h2o-table th,\n",
       "#h2o-table-18 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-18 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-18\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 19.36 %, avg score: 19.19 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.01</td>\n",
       "<td>0.5084906</td>\n",
       "<td>2.9373790</td>\n",
       "<td>2.9373790</td>\n",
       "<td>0.56875</td>\n",
       "<td>0.5570726</td>\n",
       "<td>0.56875</td>\n",
       "<td>0.5570726</td>\n",
       "<td>0.0293738</td>\n",
       "<td>0.0293738</td>\n",
       "<td>193.7378954</td>\n",
       "<td>193.7378954</td>\n",
       "<td>0.0240258</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.02</td>\n",
       "<td>0.4638636</td>\n",
       "<td>2.8405423</td>\n",
       "<td>2.8889606</td>\n",
       "<td>0.55</td>\n",
       "<td>0.4858286</td>\n",
       "<td>0.559375</td>\n",
       "<td>0.5214506</td>\n",
       "<td>0.0284054</td>\n",
       "<td>0.0577792</td>\n",
       "<td>184.0542285</td>\n",
       "<td>188.8960620</td>\n",
       "<td>0.0468507</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.03</td>\n",
       "<td>0.4383125</td>\n",
       "<td>2.3563589</td>\n",
       "<td>2.7114267</td>\n",
       "<td>0.45625</td>\n",
       "<td>0.4508089</td>\n",
       "<td>0.525</td>\n",
       "<td>0.4979034</td>\n",
       "<td>0.0235636</td>\n",
       "<td>0.0813428</td>\n",
       "<td>135.6358941</td>\n",
       "<td>171.1426727</td>\n",
       "<td>0.0636711</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.4175128</td>\n",
       "<td>2.4531956</td>\n",
       "<td>2.6468689</td>\n",
       "<td>0.475</td>\n",
       "<td>0.4279736</td>\n",
       "<td>0.5125</td>\n",
       "<td>0.4804209</td>\n",
       "<td>0.0245320</td>\n",
       "<td>0.1058748</td>\n",
       "<td>145.3195610</td>\n",
       "<td>164.6868948</td>\n",
       "<td>0.0816925</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.4040694</td>\n",
       "<td>2.4531956</td>\n",
       "<td>2.6081343</td>\n",
       "<td>0.475</td>\n",
       "<td>0.4100443</td>\n",
       "<td>0.505</td>\n",
       "<td>0.4663456</td>\n",
       "<td>0.0245320</td>\n",
       "<td>0.1304067</td>\n",
       "<td>145.3195610</td>\n",
       "<td>160.8134280</td>\n",
       "<td>0.0997138</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.3473957</td>\n",
       "<td>2.0206585</td>\n",
       "<td>2.3143964</td>\n",
       "<td>0.39125</td>\n",
       "<td>0.3727357</td>\n",
       "<td>0.448125</td>\n",
       "<td>0.4195406</td>\n",
       "<td>0.1010329</td>\n",
       "<td>0.2314396</td>\n",
       "<td>102.0658489</td>\n",
       "<td>131.4396385</td>\n",
       "<td>0.1630006</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.3094098</td>\n",
       "<td>1.7817947</td>\n",
       "<td>2.1368625</td>\n",
       "<td>0.345</td>\n",
       "<td>0.3278058</td>\n",
       "<td>0.41375</td>\n",
       "<td>0.3889623</td>\n",
       "<td>0.0890897</td>\n",
       "<td>0.3205294</td>\n",
       "<td>78.1794706</td>\n",
       "<td>113.6862492</td>\n",
       "<td>0.2114765</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.2815713</td>\n",
       "<td>1.5558425</td>\n",
       "<td>1.9916075</td>\n",
       "<td>0.30125</td>\n",
       "<td>0.2946554</td>\n",
       "<td>0.385625</td>\n",
       "<td>0.3653856</td>\n",
       "<td>0.0777921</td>\n",
       "<td>0.3983215</td>\n",
       "<td>55.5842479</td>\n",
       "<td>99.1607489</td>\n",
       "<td>0.2459420</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.2356933</td>\n",
       "<td>1.2459651</td>\n",
       "<td>1.7430600</td>\n",
       "<td>0.24125</td>\n",
       "<td>0.2581449</td>\n",
       "<td>0.3375</td>\n",
       "<td>0.3296387</td>\n",
       "<td>0.1245965</td>\n",
       "<td>0.5229180</td>\n",
       "<td>24.5965139</td>\n",
       "<td>74.3060039</td>\n",
       "<td>0.2764446</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.2015966</td>\n",
       "<td>1.1394448</td>\n",
       "<td>1.5921562</td>\n",
       "<td>0.220625</td>\n",
       "<td>0.2180556</td>\n",
       "<td>0.3082813</td>\n",
       "<td>0.3017429</td>\n",
       "<td>0.1139445</td>\n",
       "<td>0.6368625</td>\n",
       "<td>13.9444803</td>\n",
       "<td>59.2156230</td>\n",
       "<td>0.2937374</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.1717929</td>\n",
       "<td>1.0071014</td>\n",
       "<td>1.4751453</td>\n",
       "<td>0.195</td>\n",
       "<td>0.1862880</td>\n",
       "<td>0.285625</td>\n",
       "<td>0.2786519</td>\n",
       "<td>0.1007101</td>\n",
       "<td>0.7375726</td>\n",
       "<td>0.7101356</td>\n",
       "<td>47.5145255</td>\n",
       "<td>0.2946180</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.1456541</td>\n",
       "<td>0.9167205</td>\n",
       "<td>1.3820745</td>\n",
       "<td>0.1775</td>\n",
       "<td>0.1586327</td>\n",
       "<td>0.2676042</td>\n",
       "<td>0.2586487</td>\n",
       "<td>0.0916720</td>\n",
       "<td>0.8292447</td>\n",
       "<td>-8.3279535</td>\n",
       "<td>38.2074457</td>\n",
       "<td>0.2842904</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.1215011</td>\n",
       "<td>0.6552615</td>\n",
       "<td>1.2782440</td>\n",
       "<td>0.126875</td>\n",
       "<td>0.1334781</td>\n",
       "<td>0.2475</td>\n",
       "<td>0.2407672</td>\n",
       "<td>0.0655261</td>\n",
       "<td>0.8947708</td>\n",
       "<td>-34.4738541</td>\n",
       "<td>27.8244028</td>\n",
       "<td>0.2415388</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0958286</td>\n",
       "<td>0.4906391</td>\n",
       "<td>1.1797934</td>\n",
       "<td>0.095</td>\n",
       "<td>0.1088230</td>\n",
       "<td>0.2284375</td>\n",
       "<td>0.2242742</td>\n",
       "<td>0.0490639</td>\n",
       "<td>0.9438347</td>\n",
       "<td>-50.9360878</td>\n",
       "<td>17.9793415</td>\n",
       "<td>0.1783720</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0651016</td>\n",
       "<td>0.3582957</td>\n",
       "<td>1.0885159</td>\n",
       "<td>0.069375</td>\n",
       "<td>0.0812969</td>\n",
       "<td>0.2107639</td>\n",
       "<td>0.2083878</td>\n",
       "<td>0.0358296</td>\n",
       "<td>0.9796643</td>\n",
       "<td>-64.1704325</td>\n",
       "<td>8.8515888</td>\n",
       "<td>0.0987931</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0034675</td>\n",
       "<td>0.2033570</td>\n",
       "<td>1.0</td>\n",
       "<td>0.039375</td>\n",
       "<td>0.0434345</td>\n",
       "<td>0.193625</td>\n",
       "<td>0.1918925</td>\n",
       "<td>0.0203357</td>\n",
       "<td>1.0</td>\n",
       "<td>-79.6642995</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>"
      ],
      "text/plain": [
       "ModelMetricsBinomialGLM: stackedensemble\n",
       "** Reported on test data. **\n",
       "\n",
       "MSE: 0.14194955073836305\n",
       "RMSE: 0.37676192846194406\n",
       "LogLoss: 0.4459669197244253\n",
       "AUC: 0.7111584908991144\n",
       "AUCPR: 0.3659152389928349\n",
       "Gini: 0.42231698179822885\n",
       "Null degrees of freedom: 15999\n",
       "Residual degrees of freedom: 15994\n",
       "Null deviance: 15725.976585763\n",
       "Residual deviance: 14270.94143118161\n",
       "AIC: 14282.94143118161\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.19930079046274846\n",
       "       0     1     Error    Rate\n",
       "-----  ----  ----  -------  ----------------\n",
       "0      8375  4527  0.3509   (4527.0/12902.0)\n",
       "1      1089  2009  0.3515   (1089.0/3098.0)\n",
       "Total  9464  6536  0.351    (5616.0/16000.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.199301     0.417065  219\n",
       "max f2                       0.117895     0.588433  303\n",
       "max f0point5                 0.317972     0.392648  123\n",
       "max accuracy                 0.468613     0.80875   44\n",
       "max precision                0.747275     1         0\n",
       "max recall                   0.0164975    1         394\n",
       "max specificity              0.747275     1         0\n",
       "max absolute_mcc             0.256998     0.245765  171\n",
       "max min_per_class_accuracy   0.199301     0.648483  219\n",
       "max mean_per_class_accuracy  0.199301     0.648804  219\n",
       "max tns                      0.747275     12902     0\n",
       "max fns                      0.747275     3097      0\n",
       "max fps                      0.00567468   12902     399\n",
       "max tps                      0.0164975    3098      394\n",
       "max tnr                      0.747275     1         0\n",
       "max fnr                      0.747275     0.999677  0\n",
       "max fpr                      0.00567468   1         399\n",
       "max tpr                      0.0164975    1         394\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 19.36 %, avg score: 19.19 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.01                        0.508491           2.93738   2.93738            0.56875          0.557073   0.56875                     0.557073            0.0293738       0.0293738                  193.738   193.738            0.0240258\n",
       "2        0.02                        0.463864           2.84054   2.88896            0.55             0.485829   0.559375                    0.521451            0.0284054       0.0577792                  184.054   188.896            0.0468507\n",
       "3        0.03                        0.438312           2.35636   2.71143            0.45625          0.450809   0.525                       0.497903            0.0235636       0.0813428                  135.636   171.143            0.0636711\n",
       "4        0.04                        0.417513           2.4532    2.64687            0.475            0.427974   0.5125                      0.480421            0.024532        0.105875                   145.32    164.687            0.0816925\n",
       "5        0.05                        0.404069           2.4532    2.60813            0.475            0.410044   0.505                       0.466346            0.024532        0.130407                   145.32    160.813            0.0997138\n",
       "6        0.1                         0.347396           2.02066   2.3144             0.39125          0.372736   0.448125                    0.419541            0.101033        0.23144                    102.066   131.44             0.163001\n",
       "7        0.15                        0.30941            1.78179   2.13686            0.345            0.327806   0.41375                     0.388962            0.0890897       0.320529                   78.1795   113.686            0.211477\n",
       "8        0.2                         0.281571           1.55584   1.99161            0.30125          0.294655   0.385625                    0.365386            0.0777921       0.398321                   55.5842   99.1607            0.245942\n",
       "9        0.3                         0.235693           1.24597   1.74306            0.24125          0.258145   0.3375                      0.329639            0.124597        0.522918                   24.5965   74.306             0.276445\n",
       "10       0.4                         0.201597           1.13944   1.59216            0.220625         0.218056   0.308281                    0.301743            0.113944        0.636862                   13.9445   59.2156            0.293737\n",
       "11       0.5                         0.171793           1.0071    1.47515            0.195            0.186288   0.285625                    0.278652            0.10071         0.737573                   0.710136  47.5145            0.294618\n",
       "12       0.6                         0.145654           0.91672   1.38207            0.1775           0.158633   0.267604                    0.258649            0.091672        0.829245                   -8.32795  38.2074            0.28429\n",
       "13       0.7                         0.121501           0.655261  1.27824            0.126875         0.133478   0.2475                      0.240767            0.0655261       0.894771                   -34.4739  27.8244            0.241539\n",
       "14       0.8                         0.0958286          0.490639  1.17979            0.095            0.108823   0.228437                    0.224274            0.0490639       0.943835                   -50.9361  17.9793            0.178372\n",
       "15       0.9                         0.0651016          0.358296  1.08852            0.069375         0.0812969  0.210764                    0.208388            0.0358296       0.979664                   -64.1704  8.85159            0.0987931\n",
       "16       1                           0.00346748         0.203357  1                  0.039375         0.0434345  0.193625                    0.191892            0.0203357       1                          -79.6643  0                  0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf = automl.leader.model_performance(test_hf)\n",
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "560b8f74-7bb0-410b-8438-c4afb70cf508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritwikgoel/.local/lib/python3.10/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>actual</th>\n",
       "      <th>non_actual</th>\n",
       "      <th>cum_count</th>\n",
       "      <th>cum_actual</th>\n",
       "      <th>cum_non_actual</th>\n",
       "      <th>percent_cum_actual</th>\n",
       "      <th>percent_cum_non_actual</th>\n",
       "      <th>if_random</th>\n",
       "      <th>lift</th>\n",
       "      <th>K_S</th>\n",
       "      <th>gain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1600</td>\n",
       "      <td>460</td>\n",
       "      <td>1140</td>\n",
       "      <td>1600</td>\n",
       "      <td>460</td>\n",
       "      <td>1140</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.09</td>\n",
       "      <td>309.8</td>\n",
       "      <td>1.48</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1600</td>\n",
       "      <td>493</td>\n",
       "      <td>1107</td>\n",
       "      <td>3200</td>\n",
       "      <td>953</td>\n",
       "      <td>2247</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.17</td>\n",
       "      <td>619.6</td>\n",
       "      <td>1.54</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1600</td>\n",
       "      <td>513</td>\n",
       "      <td>1087</td>\n",
       "      <td>4800</td>\n",
       "      <td>1466</td>\n",
       "      <td>3334</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.26</td>\n",
       "      <td>929.4</td>\n",
       "      <td>1.58</td>\n",
       "      <td>21.0</td>\n",
       "      <td>30.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600</td>\n",
       "      <td>502</td>\n",
       "      <td>1098</td>\n",
       "      <td>6400</td>\n",
       "      <td>1968</td>\n",
       "      <td>4432</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1239.2</td>\n",
       "      <td>1.59</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1600</td>\n",
       "      <td>192</td>\n",
       "      <td>1408</td>\n",
       "      <td>8000</td>\n",
       "      <td>2160</td>\n",
       "      <td>5840</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>25.0</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1600</td>\n",
       "      <td>183</td>\n",
       "      <td>1417</td>\n",
       "      <td>9600</td>\n",
       "      <td>2343</td>\n",
       "      <td>7257</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1858.8</td>\n",
       "      <td>1.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1600</td>\n",
       "      <td>189</td>\n",
       "      <td>1411</td>\n",
       "      <td>11200</td>\n",
       "      <td>2532</td>\n",
       "      <td>8668</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.67</td>\n",
       "      <td>2168.6</td>\n",
       "      <td>1.17</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1600</td>\n",
       "      <td>189</td>\n",
       "      <td>1411</td>\n",
       "      <td>12800</td>\n",
       "      <td>2721</td>\n",
       "      <td>10079</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2478.4</td>\n",
       "      <td>1.10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1600</td>\n",
       "      <td>215</td>\n",
       "      <td>1385</td>\n",
       "      <td>14400</td>\n",
       "      <td>2936</td>\n",
       "      <td>11464</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2788.2</td>\n",
       "      <td>1.05</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1600</td>\n",
       "      <td>162</td>\n",
       "      <td>1438</td>\n",
       "      <td>16000</td>\n",
       "      <td>3098</td>\n",
       "      <td>12902</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3098.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count  actual  non_actual  cum_count  cum_actual  cum_non_actual  \\\n",
       "decile                                                                     \n",
       "0        1600     460        1140       1600         460            1140   \n",
       "1        1600     493        1107       3200         953            2247   \n",
       "2        1600     513        1087       4800        1466            3334   \n",
       "3        1600     502        1098       6400        1968            4432   \n",
       "4        1600     192        1408       8000        2160            5840   \n",
       "5        1600     183        1417       9600        2343            7257   \n",
       "6        1600     189        1411      11200        2532            8668   \n",
       "7        1600     189        1411      12800        2721           10079   \n",
       "8        1600     215        1385      14400        2936           11464   \n",
       "9        1600     162        1438      16000        3098           12902   \n",
       "\n",
       "        percent_cum_actual  percent_cum_non_actual  if_random  lift   K_S  \\\n",
       "decile                                                                      \n",
       "0                     0.15                    0.09      309.8  1.48   6.0   \n",
       "1                     0.31                    0.17      619.6  1.54  14.0   \n",
       "2                     0.47                    0.26      929.4  1.58  21.0   \n",
       "3                     0.64                    0.34     1239.2  1.59  30.0   \n",
       "4                     0.70                    0.45     1549.0  1.39  25.0   \n",
       "5                     0.76                    0.56     1858.8  1.26  20.0   \n",
       "6                     0.82                    0.67     2168.6  1.17  15.0   \n",
       "7                     0.88                    0.78     2478.4  1.10  10.0   \n",
       "8                     0.95                    0.89     2788.2  1.05   6.0   \n",
       "9                     1.00                    1.00     3098.0  1.00   0.0   \n",
       "\n",
       "         gain  \n",
       "decile         \n",
       "0       28.75  \n",
       "1       29.78  \n",
       "2       30.54  \n",
       "3       30.75  \n",
       "4       27.00  \n",
       "5       24.41  \n",
       "6       22.61  \n",
       "7       21.26  \n",
       "8       20.39  \n",
       "9       19.36  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createGains(automl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7d0d550-dd85-44ff-9eea-db23597eacb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritwikgoel/.local/lib/python3.10/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['StackedEnsemble_BestOfFamily_1_AutoML_1_20241128_130210',\n",
       " 'StackedEnsemble_AllModels_1_AutoML_1_20241128_130210',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_74',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_6',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_5',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_9',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_16',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_85',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_65',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_1',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_6',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_30',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_106',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_55',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_50',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_32',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_83',\n",
       " 'GLM_1_AutoML_1_20241128_130210',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_36',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_79',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_22',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_29',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_101',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_1',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_49',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_5',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_6',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_9',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_22',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_61',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_17',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_40',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_108',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_19',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_71',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_44',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_47',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_32',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_16',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_21',\n",
       " 'GBM_2_AutoML_1_20241128_130210',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_20',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_9',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_14',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_61',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_100',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_12',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_16',\n",
       " 'GBM_5_AutoML_1_20241128_130210',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_33',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_72',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_23',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_93',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_18',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_13',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_17',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_19',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_17',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_46',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_29',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_37',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_43',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_73',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_53',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_15',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_31',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_16',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_14',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_51',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_5',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_55',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_23',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_31',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_8',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_13',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_33',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_34',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_28',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_12',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_25',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_6',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_28',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_12',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_2',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_26',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_27',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_1',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_16',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_35',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_49',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_60',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_5',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_87',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_1',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_8',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_33',\n",
       " 'GBM_3_AutoML_1_20241128_130210',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_51',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_30',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_20',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_17',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_6',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_8',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_28',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_54',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_41',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_1',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_12',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_58',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_52',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_2',\n",
       " 'XGBoost_3_AutoML_1_20241128_130210',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_40',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_14',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_104',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_12',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_62',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_50',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_2',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_39',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_5',\n",
       " 'DeepLearning_1_AutoML_1_20241128_130210',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_8',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_27',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_7',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_35',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_68',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_24',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_23',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_82',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_68',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_62',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_69',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_45',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_44',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_24',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_52',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_30',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_71',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_22',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_20',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_24',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_15',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_28',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_33',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_26',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_36',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_65',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_23',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_17',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_23',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_95',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_99',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_63',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_25',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_54',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_86',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_7',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_32',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_25',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_81',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_37',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_38',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_91',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_27',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_31',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_14',\n",
       " 'GBM_4_AutoML_1_20241128_130210',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_2',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_35',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_27',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_7',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_22',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_96',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_77',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_13',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_24',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_36',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_7',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_48',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_3',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_35',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_19',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_18',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_28',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_69',\n",
       " 'GBM_1_AutoML_1_20241128_130210',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_39',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_31',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_42',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_10',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_13',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_25',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_59',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_18',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_15',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_10',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_34',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_20',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_46',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_26',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_31',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_102',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_15',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_2',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_7',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_3',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_57',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_67',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_20',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_56',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_90',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_30',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_63',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_94',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_64',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_97',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_30',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_10',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_70',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_66',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_34',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_36',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_10',\n",
       " 'DRF_1_AutoML_1_20241128_130210',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_9',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_15',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_60',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_53',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_36',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_3',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_18',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_18',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_32',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_9',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_26',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_11',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_19',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_84',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_75',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_57',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_34',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_34',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_26',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_35',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_22',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_29',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_4',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_4',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_67',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_14',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_11',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_33',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_76',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_38',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_27',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_24',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_107',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_8',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_78',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_13',\n",
       " 'XRT_1_AutoML_1_20241128_130210',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_29',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_80',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_48',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_3',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_4',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_41',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_105',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_64',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_29',\n",
       " 'GBM_grid_1_AutoML_1_20241128_130210_model_3',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_47',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_92',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_11',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_10',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_19',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_11',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_4',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_11',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_43',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_70',\n",
       " 'XGBoost_2_AutoML_1_20241128_130210',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_21',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_89',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_72',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_32',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_4',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_59',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_103',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_98',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_58',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_56',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_66',\n",
       " 'XGBoost_1_AutoML_1_20241128_130210',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_25',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_42',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_88',\n",
       " 'DeepLearning_grid_1_AutoML_1_20241128_130210_model_21',\n",
       " 'XGBoost_grid_1_AutoML_1_20241128_130210_model_45',\n",
       " 'DeepLearning_grid_2_AutoML_1_20241128_130210_model_21',\n",
       " 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_21']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ids = list(automl.leaderboard['model_id'].as_data_frame().iloc[:,0])\n",
    "model_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78d473cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'StackedEnsemble_BestOfFamily_1_AutoML_1_20241128_130210'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the first model as the best model (assumed to be sorted by performance)\n",
    "best_model_id = model_ids[0]\n",
    "best_model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28d43238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best model using its ID\n",
    "best_model = h2o.get_model(best_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b55b702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': {'default': None,\n",
       "  'actual': {'__meta': {'schema_version': 3,\n",
       "    'schema_name': 'ModelKeyV3',\n",
       "    'schema_type': 'Key<Model>'},\n",
       "   'name': 'StackedEnsemble_BestOfFamily_1_AutoML_1_20241128_130210',\n",
       "   'type': 'Key<Model>',\n",
       "   'URL': '/3/Models/StackedEnsemble_BestOfFamily_1_AutoML_1_20241128_130210'},\n",
       "  'input': None},\n",
       " 'training_frame': {'default': None,\n",
       "  'actual': {'__meta': {'schema_version': 3,\n",
       "    'schema_name': 'FrameKeyV3',\n",
       "    'schema_type': 'Key<Frame>'},\n",
       "   'name': 'AutoML_1_20241128_130210_training_py_1_sid_a941',\n",
       "   'type': 'Key<Frame>',\n",
       "   'URL': '/3/Frames/AutoML_1_20241128_130210_training_py_1_sid_a941'},\n",
       "  'input': {'__meta': {'schema_version': 3,\n",
       "    'schema_name': 'FrameKeyV3',\n",
       "    'schema_type': 'Key<Frame>'},\n",
       "   'name': 'AutoML_1_20241128_130210_training_py_1_sid_a941',\n",
       "   'type': 'Key<Frame>',\n",
       "   'URL': '/3/Frames/AutoML_1_20241128_130210_training_py_1_sid_a941'}},\n",
       " 'response_column': {'default': None,\n",
       "  'actual': {'__meta': {'schema_version': 3,\n",
       "    'schema_name': 'ColSpecifierV3',\n",
       "    'schema_type': 'VecSpecifier'},\n",
       "   'column_name': 'loan_default',\n",
       "   'is_member_of_frames': None},\n",
       "  'input': {'__meta': {'schema_version': 3,\n",
       "    'schema_name': 'ColSpecifierV3',\n",
       "    'schema_type': 'VecSpecifier'},\n",
       "   'column_name': 'loan_default',\n",
       "   'is_member_of_frames': None}},\n",
       " 'validation_frame': {'default': None, 'actual': None, 'input': None},\n",
       " 'blending_frame': {'default': None, 'actual': None, 'input': None},\n",
       " 'base_models': {'default': [],\n",
       "  'actual': [{'__meta': {'schema_version': 3,\n",
       "     'schema_name': 'KeyV3',\n",
       "     'schema_type': 'Key<Keyed>'},\n",
       "    'name': 'XGBoost_grid_1_AutoML_1_20241128_130210_model_74',\n",
       "    'type': 'Key<Keyed>',\n",
       "    'URL': None},\n",
       "   {'__meta': {'schema_version': 3,\n",
       "     'schema_name': 'KeyV3',\n",
       "     'schema_type': 'Key<Keyed>'},\n",
       "    'name': 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_6',\n",
       "    'type': 'Key<Keyed>',\n",
       "    'URL': None},\n",
       "   {'__meta': {'schema_version': 3,\n",
       "     'schema_name': 'KeyV3',\n",
       "     'schema_type': 'Key<Keyed>'},\n",
       "    'name': 'GBM_grid_1_AutoML_1_20241128_130210_model_65',\n",
       "    'type': 'Key<Keyed>',\n",
       "    'URL': None},\n",
       "   {'__meta': {'schema_version': 3,\n",
       "     'schema_name': 'KeyV3',\n",
       "     'schema_type': 'Key<Keyed>'},\n",
       "    'name': 'GLM_1_AutoML_1_20241128_130210',\n",
       "    'type': 'Key<Keyed>',\n",
       "    'URL': None},\n",
       "   {'__meta': {'schema_version': 3,\n",
       "     'schema_name': 'KeyV3',\n",
       "     'schema_type': 'Key<Keyed>'},\n",
       "    'name': 'DRF_1_AutoML_1_20241128_130210',\n",
       "    'type': 'Key<Keyed>',\n",
       "    'URL': None},\n",
       "   {'__meta': {'schema_version': 3,\n",
       "     'schema_name': 'KeyV3',\n",
       "     'schema_type': 'Key<Keyed>'},\n",
       "    'name': 'XRT_1_AutoML_1_20241128_130210',\n",
       "    'type': 'Key<Keyed>',\n",
       "    'URL': None}],\n",
       "  'input': [{'__meta': {'schema_version': 3,\n",
       "     'schema_name': 'KeyV3',\n",
       "     'schema_type': 'Key<Keyed>'},\n",
       "    'name': 'XGBoost_grid_1_AutoML_1_20241128_130210_model_74',\n",
       "    'type': 'Key<Keyed>',\n",
       "    'URL': None},\n",
       "   {'__meta': {'schema_version': 3,\n",
       "     'schema_name': 'KeyV3',\n",
       "     'schema_type': 'Key<Keyed>'},\n",
       "    'name': 'DeepLearning_grid_3_AutoML_1_20241128_130210_model_6',\n",
       "    'type': 'Key<Keyed>',\n",
       "    'URL': None},\n",
       "   {'__meta': {'schema_version': 3,\n",
       "     'schema_name': 'KeyV3',\n",
       "     'schema_type': 'Key<Keyed>'},\n",
       "    'name': 'GBM_grid_1_AutoML_1_20241128_130210_model_65',\n",
       "    'type': 'Key<Keyed>',\n",
       "    'URL': None},\n",
       "   {'__meta': {'schema_version': 3,\n",
       "     'schema_name': 'KeyV3',\n",
       "     'schema_type': 'Key<Keyed>'},\n",
       "    'name': 'GLM_1_AutoML_1_20241128_130210',\n",
       "    'type': 'Key<Keyed>',\n",
       "    'URL': None},\n",
       "   {'__meta': {'schema_version': 3,\n",
       "     'schema_name': 'KeyV3',\n",
       "     'schema_type': 'Key<Keyed>'},\n",
       "    'name': 'DRF_1_AutoML_1_20241128_130210',\n",
       "    'type': 'Key<Keyed>',\n",
       "    'URL': None},\n",
       "   {'__meta': {'schema_version': 3,\n",
       "     'schema_name': 'KeyV3',\n",
       "     'schema_type': 'Key<Keyed>'},\n",
       "    'name': 'XRT_1_AutoML_1_20241128_130210',\n",
       "    'type': 'Key<Keyed>',\n",
       "    'URL': None}]},\n",
       " 'metalearner_algorithm': {'default': 'AUTO',\n",
       "  'actual': 'glm',\n",
       "  'input': 'AUTO'},\n",
       " 'metalearner_nfolds': {'default': 0, 'actual': 5, 'input': 5},\n",
       " 'metalearner_fold_assignment': {'default': None,\n",
       "  'actual': None,\n",
       "  'input': None},\n",
       " 'metalearner_fold_column': {'default': None, 'actual': None, 'input': None},\n",
       " 'metalearner_params': {'default': '', 'actual': '', 'input': ''},\n",
       " 'metalearner_transform': {'default': 'NONE',\n",
       "  'actual': 'Logit',\n",
       "  'input': 'Logit'},\n",
       " 'max_runtime_secs': {'default': 0.0, 'actual': 0.0, 'input': 0.0},\n",
       " 'weights_column': {'default': None, 'actual': None, 'input': None},\n",
       " 'offset_column': {'default': None, 'actual': None, 'input': None},\n",
       " 'custom_metric_func': {'default': None, 'actual': None, 'input': None},\n",
       " 'seed': {'default': -1, 'actual': 54, 'input': 54},\n",
       " 'score_training_samples': {'default': 10000, 'actual': 10000, 'input': 10000},\n",
       " 'keep_levelone_frame': {'default': False, 'actual': True, 'input': True},\n",
       " 'export_checkpoints_dir': {'default': None, 'actual': None, 'input': None},\n",
       " 'auc_type': {'default': 'AUTO', 'actual': 'AUTO', 'input': 'AUTO'},\n",
       " 'gainslift_bins': {'default': -1, 'actual': -1, 'input': -1}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28b257b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritwikgoel/.local/lib/python3.10/site-packages/h2o/job.py:81: UserWarning: Test/Validation dataset column 'MB007' has levels not trained on: [\"AND\", \"APPLE\", \"BOWAY\", \"DOOVL5PRO\", \"MANN\", \"MC-X7MINI\", \"RAMOS\", \"TINAI\", \"VOLTE\"]\n",
      "  warnings.warn(w)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class='dataframe'>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">      p0</th><th style=\"text-align: right;\">       p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.778726</td><td style=\"text-align: right;\">0.221274 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.917351</td><td style=\"text-align: right;\">0.0826493</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.909479</td><td style=\"text-align: right;\">0.0905208</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.758802</td><td style=\"text-align: right;\">0.241198 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.69856 </td><td style=\"text-align: right;\">0.30144  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.764238</td><td style=\"text-align: right;\">0.235762 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.959772</td><td style=\"text-align: right;\">0.0402283</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.985171</td><td style=\"text-align: right;\">0.0148294</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.753894</td><td style=\"text-align: right;\">0.246106 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.872068</td><td style=\"text-align: right;\">0.127932 </td></tr>\n",
       "</tbody>\n",
       "</table><pre style='font-size: smaller; margin-bottom: 1em;'>[16000 rows x 3 columns]</pre>"
      ],
      "text/plain": [
       "  predict        p0         p1\n",
       "---------  --------  ---------\n",
       "        1  0.778726  0.221274\n",
       "        0  0.917351  0.0826493\n",
       "        0  0.909479  0.0905208\n",
       "        1  0.758802  0.241198\n",
       "        1  0.69856   0.30144\n",
       "        1  0.764238  0.235762\n",
       "        0  0.959772  0.0402283\n",
       "        0  0.985171  0.0148294\n",
       "        1  0.753894  0.246106\n",
       "        0  0.872068  0.127932\n",
       "[16000 rows x 3 columns]\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict(test_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9e070dc-d2b8-4e2a-9422-4988d3327eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomialGLM: stackedensemble\n",
       "** Reported on test data. **\n",
       "\n",
       "MSE: 0.14194955073836305\n",
       "RMSE: 0.37676192846194406\n",
       "LogLoss: 0.4459669197244253\n",
       "AUC: 0.7111584908991144\n",
       "AUCPR: 0.3659152389928349\n",
       "Gini: 0.42231698179822885\n",
       "Null degrees of freedom: 15999\n",
       "Residual degrees of freedom: 15994\n",
       "Null deviance: 15725.976585763\n",
       "Residual deviance: 14270.94143118161\n",
       "AIC: 14282.94143118161</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-19.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-19 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-19 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-19 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-19 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-19 .h2o-table th,\n",
       "#h2o-table-19 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-19 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-19\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.19930079046274846</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>0</th>\n",
       "<th>1</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>0</td>\n",
       "<td>8375.0</td>\n",
       "<td>4527.0</td>\n",
       "<td>0.3509</td>\n",
       "<td> (4527.0/12902.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>1089.0</td>\n",
       "<td>2009.0</td>\n",
       "<td>0.3515</td>\n",
       "<td> (1089.0/3098.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>9464.0</td>\n",
       "<td>6536.0</td>\n",
       "<td>0.351</td>\n",
       "<td> (5616.0/16000.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-20.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-20 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-20 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-20 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-20 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-20 .h2o-table th,\n",
       "#h2o-table-20 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-20 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-20\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.1993008</td>\n",
       "<td>0.4170646</td>\n",
       "<td>219.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1178950</td>\n",
       "<td>0.5884327</td>\n",
       "<td>303.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3179721</td>\n",
       "<td>0.3926483</td>\n",
       "<td>123.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4686127</td>\n",
       "<td>0.80875</td>\n",
       "<td>44.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.7472745</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0164975</td>\n",
       "<td>1.0</td>\n",
       "<td>394.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.7472745</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2569984</td>\n",
       "<td>0.2457651</td>\n",
       "<td>171.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1993008</td>\n",
       "<td>0.6484829</td>\n",
       "<td>219.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1993008</td>\n",
       "<td>0.6488035</td>\n",
       "<td>219.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.7472745</td>\n",
       "<td>12902.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.7472745</td>\n",
       "<td>3097.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0056747</td>\n",
       "<td>12902.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0164975</td>\n",
       "<td>3098.0</td>\n",
       "<td>394.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.7472745</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.7472745</td>\n",
       "<td>0.9996772</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0056747</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0164975</td>\n",
       "<td>1.0</td>\n",
       "<td>394.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-21.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-21 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-21 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-21 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-21 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-21 .h2o-table th,\n",
       "#h2o-table-21 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-21 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-21\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 19.36 %, avg score: 19.19 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.01</td>\n",
       "<td>0.5084906</td>\n",
       "<td>2.9373790</td>\n",
       "<td>2.9373790</td>\n",
       "<td>0.56875</td>\n",
       "<td>0.5570726</td>\n",
       "<td>0.56875</td>\n",
       "<td>0.5570726</td>\n",
       "<td>0.0293738</td>\n",
       "<td>0.0293738</td>\n",
       "<td>193.7378954</td>\n",
       "<td>193.7378954</td>\n",
       "<td>0.0240258</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.02</td>\n",
       "<td>0.4638636</td>\n",
       "<td>2.8405423</td>\n",
       "<td>2.8889606</td>\n",
       "<td>0.55</td>\n",
       "<td>0.4858286</td>\n",
       "<td>0.559375</td>\n",
       "<td>0.5214506</td>\n",
       "<td>0.0284054</td>\n",
       "<td>0.0577792</td>\n",
       "<td>184.0542285</td>\n",
       "<td>188.8960620</td>\n",
       "<td>0.0468507</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.03</td>\n",
       "<td>0.4383125</td>\n",
       "<td>2.3563589</td>\n",
       "<td>2.7114267</td>\n",
       "<td>0.45625</td>\n",
       "<td>0.4508089</td>\n",
       "<td>0.525</td>\n",
       "<td>0.4979034</td>\n",
       "<td>0.0235636</td>\n",
       "<td>0.0813428</td>\n",
       "<td>135.6358941</td>\n",
       "<td>171.1426727</td>\n",
       "<td>0.0636711</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.04</td>\n",
       "<td>0.4175128</td>\n",
       "<td>2.4531956</td>\n",
       "<td>2.6468689</td>\n",
       "<td>0.475</td>\n",
       "<td>0.4279736</td>\n",
       "<td>0.5125</td>\n",
       "<td>0.4804209</td>\n",
       "<td>0.0245320</td>\n",
       "<td>0.1058748</td>\n",
       "<td>145.3195610</td>\n",
       "<td>164.6868948</td>\n",
       "<td>0.0816925</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.4040694</td>\n",
       "<td>2.4531956</td>\n",
       "<td>2.6081343</td>\n",
       "<td>0.475</td>\n",
       "<td>0.4100443</td>\n",
       "<td>0.505</td>\n",
       "<td>0.4663456</td>\n",
       "<td>0.0245320</td>\n",
       "<td>0.1304067</td>\n",
       "<td>145.3195610</td>\n",
       "<td>160.8134280</td>\n",
       "<td>0.0997138</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.3473957</td>\n",
       "<td>2.0206585</td>\n",
       "<td>2.3143964</td>\n",
       "<td>0.39125</td>\n",
       "<td>0.3727357</td>\n",
       "<td>0.448125</td>\n",
       "<td>0.4195406</td>\n",
       "<td>0.1010329</td>\n",
       "<td>0.2314396</td>\n",
       "<td>102.0658489</td>\n",
       "<td>131.4396385</td>\n",
       "<td>0.1630006</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.3094098</td>\n",
       "<td>1.7817947</td>\n",
       "<td>2.1368625</td>\n",
       "<td>0.345</td>\n",
       "<td>0.3278058</td>\n",
       "<td>0.41375</td>\n",
       "<td>0.3889623</td>\n",
       "<td>0.0890897</td>\n",
       "<td>0.3205294</td>\n",
       "<td>78.1794706</td>\n",
       "<td>113.6862492</td>\n",
       "<td>0.2114765</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.2815713</td>\n",
       "<td>1.5558425</td>\n",
       "<td>1.9916075</td>\n",
       "<td>0.30125</td>\n",
       "<td>0.2946554</td>\n",
       "<td>0.385625</td>\n",
       "<td>0.3653856</td>\n",
       "<td>0.0777921</td>\n",
       "<td>0.3983215</td>\n",
       "<td>55.5842479</td>\n",
       "<td>99.1607489</td>\n",
       "<td>0.2459420</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.2356933</td>\n",
       "<td>1.2459651</td>\n",
       "<td>1.7430600</td>\n",
       "<td>0.24125</td>\n",
       "<td>0.2581449</td>\n",
       "<td>0.3375</td>\n",
       "<td>0.3296387</td>\n",
       "<td>0.1245965</td>\n",
       "<td>0.5229180</td>\n",
       "<td>24.5965139</td>\n",
       "<td>74.3060039</td>\n",
       "<td>0.2764446</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.2015966</td>\n",
       "<td>1.1394448</td>\n",
       "<td>1.5921562</td>\n",
       "<td>0.220625</td>\n",
       "<td>0.2180556</td>\n",
       "<td>0.3082813</td>\n",
       "<td>0.3017429</td>\n",
       "<td>0.1139445</td>\n",
       "<td>0.6368625</td>\n",
       "<td>13.9444803</td>\n",
       "<td>59.2156230</td>\n",
       "<td>0.2937374</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.1717929</td>\n",
       "<td>1.0071014</td>\n",
       "<td>1.4751453</td>\n",
       "<td>0.195</td>\n",
       "<td>0.1862880</td>\n",
       "<td>0.285625</td>\n",
       "<td>0.2786519</td>\n",
       "<td>0.1007101</td>\n",
       "<td>0.7375726</td>\n",
       "<td>0.7101356</td>\n",
       "<td>47.5145255</td>\n",
       "<td>0.2946180</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.1456541</td>\n",
       "<td>0.9167205</td>\n",
       "<td>1.3820745</td>\n",
       "<td>0.1775</td>\n",
       "<td>0.1586327</td>\n",
       "<td>0.2676042</td>\n",
       "<td>0.2586487</td>\n",
       "<td>0.0916720</td>\n",
       "<td>0.8292447</td>\n",
       "<td>-8.3279535</td>\n",
       "<td>38.2074457</td>\n",
       "<td>0.2842904</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.1215011</td>\n",
       "<td>0.6552615</td>\n",
       "<td>1.2782440</td>\n",
       "<td>0.126875</td>\n",
       "<td>0.1334781</td>\n",
       "<td>0.2475</td>\n",
       "<td>0.2407672</td>\n",
       "<td>0.0655261</td>\n",
       "<td>0.8947708</td>\n",
       "<td>-34.4738541</td>\n",
       "<td>27.8244028</td>\n",
       "<td>0.2415388</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0958286</td>\n",
       "<td>0.4906391</td>\n",
       "<td>1.1797934</td>\n",
       "<td>0.095</td>\n",
       "<td>0.1088230</td>\n",
       "<td>0.2284375</td>\n",
       "<td>0.2242742</td>\n",
       "<td>0.0490639</td>\n",
       "<td>0.9438347</td>\n",
       "<td>-50.9360878</td>\n",
       "<td>17.9793415</td>\n",
       "<td>0.1783720</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0651016</td>\n",
       "<td>0.3582957</td>\n",
       "<td>1.0885159</td>\n",
       "<td>0.069375</td>\n",
       "<td>0.0812969</td>\n",
       "<td>0.2107639</td>\n",
       "<td>0.2083878</td>\n",
       "<td>0.0358296</td>\n",
       "<td>0.9796643</td>\n",
       "<td>-64.1704325</td>\n",
       "<td>8.8515888</td>\n",
       "<td>0.0987931</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0034675</td>\n",
       "<td>0.2033570</td>\n",
       "<td>1.0</td>\n",
       "<td>0.039375</td>\n",
       "<td>0.0434345</td>\n",
       "<td>0.193625</td>\n",
       "<td>0.1918925</td>\n",
       "<td>0.0203357</td>\n",
       "<td>1.0</td>\n",
       "<td>-79.6642995</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>"
      ],
      "text/plain": [
       "ModelMetricsBinomialGLM: stackedensemble\n",
       "** Reported on test data. **\n",
       "\n",
       "MSE: 0.14194955073836305\n",
       "RMSE: 0.37676192846194406\n",
       "LogLoss: 0.4459669197244253\n",
       "AUC: 0.7111584908991144\n",
       "AUCPR: 0.3659152389928349\n",
       "Gini: 0.42231698179822885\n",
       "Null degrees of freedom: 15999\n",
       "Residual degrees of freedom: 15994\n",
       "Null deviance: 15725.976585763\n",
       "Residual deviance: 14270.94143118161\n",
       "AIC: 14282.94143118161\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.19930079046274846\n",
       "       0     1     Error    Rate\n",
       "-----  ----  ----  -------  ----------------\n",
       "0      8375  4527  0.3509   (4527.0/12902.0)\n",
       "1      1089  2009  0.3515   (1089.0/3098.0)\n",
       "Total  9464  6536  0.351    (5616.0/16000.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.199301     0.417065  219\n",
       "max f2                       0.117895     0.588433  303\n",
       "max f0point5                 0.317972     0.392648  123\n",
       "max accuracy                 0.468613     0.80875   44\n",
       "max precision                0.747275     1         0\n",
       "max recall                   0.0164975    1         394\n",
       "max specificity              0.747275     1         0\n",
       "max absolute_mcc             0.256998     0.245765  171\n",
       "max min_per_class_accuracy   0.199301     0.648483  219\n",
       "max mean_per_class_accuracy  0.199301     0.648804  219\n",
       "max tns                      0.747275     12902     0\n",
       "max fns                      0.747275     3097      0\n",
       "max fps                      0.00567468   12902     399\n",
       "max tps                      0.0164975    3098      394\n",
       "max tnr                      0.747275     1         0\n",
       "max fnr                      0.747275     0.999677  0\n",
       "max fpr                      0.00567468   1         399\n",
       "max tpr                      0.0164975    1         394\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 19.36 %, avg score: 19.19 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.01                        0.508491           2.93738   2.93738            0.56875          0.557073   0.56875                     0.557073            0.0293738       0.0293738                  193.738   193.738            0.0240258\n",
       "2        0.02                        0.463864           2.84054   2.88896            0.55             0.485829   0.559375                    0.521451            0.0284054       0.0577792                  184.054   188.896            0.0468507\n",
       "3        0.03                        0.438312           2.35636   2.71143            0.45625          0.450809   0.525                       0.497903            0.0235636       0.0813428                  135.636   171.143            0.0636711\n",
       "4        0.04                        0.417513           2.4532    2.64687            0.475            0.427974   0.5125                      0.480421            0.024532        0.105875                   145.32    164.687            0.0816925\n",
       "5        0.05                        0.404069           2.4532    2.60813            0.475            0.410044   0.505                       0.466346            0.024532        0.130407                   145.32    160.813            0.0997138\n",
       "6        0.1                         0.347396           2.02066   2.3144             0.39125          0.372736   0.448125                    0.419541            0.101033        0.23144                    102.066   131.44             0.163001\n",
       "7        0.15                        0.30941            1.78179   2.13686            0.345            0.327806   0.41375                     0.388962            0.0890897       0.320529                   78.1795   113.686            0.211477\n",
       "8        0.2                         0.281571           1.55584   1.99161            0.30125          0.294655   0.385625                    0.365386            0.0777921       0.398321                   55.5842   99.1607            0.245942\n",
       "9        0.3                         0.235693           1.24597   1.74306            0.24125          0.258145   0.3375                      0.329639            0.124597        0.522918                   24.5965   74.306             0.276445\n",
       "10       0.4                         0.201597           1.13944   1.59216            0.220625         0.218056   0.308281                    0.301743            0.113944        0.636862                   13.9445   59.2156            0.293737\n",
       "11       0.5                         0.171793           1.0071    1.47515            0.195            0.186288   0.285625                    0.278652            0.10071         0.737573                   0.710136  47.5145            0.294618\n",
       "12       0.6                         0.145654           0.91672   1.38207            0.1775           0.158633   0.267604                    0.258649            0.091672        0.829245                   -8.32795  38.2074            0.28429\n",
       "13       0.7                         0.121501           0.655261  1.27824            0.126875         0.133478   0.2475                      0.240767            0.0655261       0.894771                   -34.4739  27.8244            0.241539\n",
       "14       0.8                         0.0958286          0.490639  1.17979            0.095            0.108823   0.228437                    0.224274            0.0490639       0.943835                   -50.9361  17.9793            0.178372\n",
       "15       0.9                         0.0651016          0.358296  1.08852            0.069375         0.0812969  0.210764                    0.208388            0.0358296       0.979664                   -64.1704  8.85159            0.0987931\n",
       "16       1                           0.00346748         0.203357  1                  0.039375         0.0434345  0.193625                    0.191892            0.0203357       1                          -79.6643  0                  0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.model_performance(test_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c4bceb5-1fd2-41f8-87dd-1f91b6592050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>actual</th>\n",
       "      <th>non_actual</th>\n",
       "      <th>cum_count</th>\n",
       "      <th>cum_actual</th>\n",
       "      <th>cum_non_actual</th>\n",
       "      <th>percent_cum_actual</th>\n",
       "      <th>percent_cum_non_actual</th>\n",
       "      <th>if_random</th>\n",
       "      <th>lift</th>\n",
       "      <th>K_S</th>\n",
       "      <th>gain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1600</td>\n",
       "      <td>460</td>\n",
       "      <td>1140</td>\n",
       "      <td>1600</td>\n",
       "      <td>460</td>\n",
       "      <td>1140</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.09</td>\n",
       "      <td>309.8</td>\n",
       "      <td>1.48</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1600</td>\n",
       "      <td>493</td>\n",
       "      <td>1107</td>\n",
       "      <td>3200</td>\n",
       "      <td>953</td>\n",
       "      <td>2247</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.17</td>\n",
       "      <td>619.6</td>\n",
       "      <td>1.54</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1600</td>\n",
       "      <td>513</td>\n",
       "      <td>1087</td>\n",
       "      <td>4800</td>\n",
       "      <td>1466</td>\n",
       "      <td>3334</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.26</td>\n",
       "      <td>929.4</td>\n",
       "      <td>1.58</td>\n",
       "      <td>21.0</td>\n",
       "      <td>30.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600</td>\n",
       "      <td>502</td>\n",
       "      <td>1098</td>\n",
       "      <td>6400</td>\n",
       "      <td>1968</td>\n",
       "      <td>4432</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1239.2</td>\n",
       "      <td>1.59</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1600</td>\n",
       "      <td>192</td>\n",
       "      <td>1408</td>\n",
       "      <td>8000</td>\n",
       "      <td>2160</td>\n",
       "      <td>5840</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>25.0</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1600</td>\n",
       "      <td>183</td>\n",
       "      <td>1417</td>\n",
       "      <td>9600</td>\n",
       "      <td>2343</td>\n",
       "      <td>7257</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1858.8</td>\n",
       "      <td>1.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1600</td>\n",
       "      <td>189</td>\n",
       "      <td>1411</td>\n",
       "      <td>11200</td>\n",
       "      <td>2532</td>\n",
       "      <td>8668</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.67</td>\n",
       "      <td>2168.6</td>\n",
       "      <td>1.17</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1600</td>\n",
       "      <td>189</td>\n",
       "      <td>1411</td>\n",
       "      <td>12800</td>\n",
       "      <td>2721</td>\n",
       "      <td>10079</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2478.4</td>\n",
       "      <td>1.10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1600</td>\n",
       "      <td>215</td>\n",
       "      <td>1385</td>\n",
       "      <td>14400</td>\n",
       "      <td>2936</td>\n",
       "      <td>11464</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2788.2</td>\n",
       "      <td>1.05</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1600</td>\n",
       "      <td>162</td>\n",
       "      <td>1438</td>\n",
       "      <td>16000</td>\n",
       "      <td>3098</td>\n",
       "      <td>12902</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3098.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count  actual  non_actual  cum_count  cum_actual  cum_non_actual  \\\n",
       "decile                                                                     \n",
       "0        1600     460        1140       1600         460            1140   \n",
       "1        1600     493        1107       3200         953            2247   \n",
       "2        1600     513        1087       4800        1466            3334   \n",
       "3        1600     502        1098       6400        1968            4432   \n",
       "4        1600     192        1408       8000        2160            5840   \n",
       "5        1600     183        1417       9600        2343            7257   \n",
       "6        1600     189        1411      11200        2532            8668   \n",
       "7        1600     189        1411      12800        2721           10079   \n",
       "8        1600     215        1385      14400        2936           11464   \n",
       "9        1600     162        1438      16000        3098           12902   \n",
       "\n",
       "        percent_cum_actual  percent_cum_non_actual  if_random  lift   K_S  \\\n",
       "decile                                                                      \n",
       "0                     0.15                    0.09      309.8  1.48   6.0   \n",
       "1                     0.31                    0.17      619.6  1.54  14.0   \n",
       "2                     0.47                    0.26      929.4  1.58  21.0   \n",
       "3                     0.64                    0.34     1239.2  1.59  30.0   \n",
       "4                     0.70                    0.45     1549.0  1.39  25.0   \n",
       "5                     0.76                    0.56     1858.8  1.26  20.0   \n",
       "6                     0.82                    0.67     2168.6  1.17  15.0   \n",
       "7                     0.88                    0.78     2478.4  1.10  10.0   \n",
       "8                     0.95                    0.89     2788.2  1.05   6.0   \n",
       "9                     1.00                    1.00     3098.0  1.00   0.0   \n",
       "\n",
       "         gain  \n",
       "decile         \n",
       "0       28.75  \n",
       "1       29.78  \n",
       "2       30.54  \n",
       "3       30.75  \n",
       "4       27.00  \n",
       "5       24.41  \n",
       "6       22.61  \n",
       "7       21.26  \n",
       "8       20.39  \n",
       "9       19.36  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createGains(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93d41d24-3460-4ffb-817e-ff48035bdeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritwikgoel/.local/lib/python3.10/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "███████████████████████████████████████████| (done) 100%\n",
      "\n",
      "   * ROC curve: Plots the true positive rate (TPR) vs. false positive rate (FPR)\n",
      "   * AUC: Area under the ROC curve (0.5: random, 1.0: perfect accuracy)\n",
      "   * Recall (R): True Positives / (True Positives + False Negatives)\n",
      "\n",
      "ROC AUC: 0.7112\n",
      "Average Precision (Precision-Recall AUC): 0.3661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritwikgoel/.local/lib/python3.10/site-packages/h2o/job.py:81: UserWarning: Test/Validation dataset column 'MB007' has levels not trained on: [\"AND\", \"APPLE\", \"BOWAY\", \"DOOVL5PRO\", \"MANN\", \"MC-X7MINI\", \"RAMOS\", \"TINAI\", \"VOLTE\"]\n",
      "  warnings.warn(w)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ROC_AUC(best_model,test_hf,'loan_default')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9d0662-0c1e-43a7-bdcc-4a80dd14e161",
   "metadata": {},
   "source": [
    "### AutoML Leaderboard Results\n",
    "\n",
    "After completing the AutoML process, the leaderboard ranks models based on their performance on the test dataset.\n",
    "\n",
    "#### Key Observations:\n",
    "- The best model (Stacked Ensemble) achieved an AUC score of `0.7112` and an AUCPR score of `0.3661`, outperforming all other models.\n",
    "- Additional high-ranking models leveraged ensemble methods such as XGBoost and Gradient Boosting Machines, highlighting the power of leveraging multiple algorithms.\n",
    "\n",
    "These results emphasize AutoML's ability to identify complex patterns in the data efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de371a2a-ec5e-4719-9ce8-ea2e3237185b",
   "metadata": {},
   "source": [
    "### Comparison: AutoML vs. GLM\n",
    "\n",
    "#### Performance Metrics:\n",
    "- **GLM**: AUC = `0.6981`, AUCPR = `0.3668`\n",
    "- **AutoML Best Model**: AUC = `0.7112`, AUCPR = `0.3661`\n",
    "\n",
    "#### Key Takeaways:\n",
    "1. **AUC Comparison**: The AutoML model slightly outperformed the GLM model in terms of AUC, indicating better discrimination between classes.\n",
    "2. **AUCPR Comparison**: The GLM model demonstrated a slightly better precision-recall trade-off with an AUCPR of `0.3668` compared to `0.3661` for AutoML.\n",
    "3. **Insights**: AutoML's marginal improvement in AUC highlights its ability to identify subtle patterns, though the GLM model's performance remains competitive, especially in recall-heavy tasks.\n",
    "\n",
    "This comparison suggests that while AutoML provides a slight edge in overall discrimination, GLM is nearly as effective, offering the advantage of simplicity and interpretability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ad1611-dd03-45e1-98e8-2b11c010188f",
   "metadata": {},
   "source": [
    "### Takeaways and Future Considerations\n",
    "\n",
    "#### Summary:\n",
    "1. **Performance Gap**: AutoML's AUC score (`0.7112`) reflects its ability to slightly outperform GLM, but the AUCPR scores (`0.3668` vs. `0.3661`) suggest that both models handle imbalanced data comparably in terms of precision-recall trade-offs.\n",
    "2. **Model Trade-offs**: The GLM model remains a strong baseline, offering simplicity and interpretability, while AutoML provides incremental improvements by leveraging advanced algorithms.\n",
    "3. **Application Context**: Depending on the problem requirements, the choice of model could balance between AutoML's slight performance advantage and GLM's interpretability.\n",
    "\n",
    "#### Future Considerations:\n",
    "- **Model Interpretation**: Perform feature importance analysis for both models to understand the driving factors behind their predictions.\n",
    "- **Model Deployment**: Consider deploying the AutoML model for scenarios requiring higher discrimination and GLM for scenarios prioritizing interpretability.\n",
    "- **Broader Evaluation**: Extend the analysis to other datasets or domains to assess the generalizability of these findings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f88d09-5368-4f36-b480-8547cddfb782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f145f-afa1-48a6-b3e2-a5870047fc2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74568c06-d4d8-4ee3-bc83-1299a4d44306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de924d74-b5bf-44ce-bf29-6622961eee35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a949325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a599f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd5e46f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b36629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b6540c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
